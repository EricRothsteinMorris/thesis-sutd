%!TEX root = ../main.tex
% Chapter Template

%\newcommand{\branch}[3]{\ensuremath{{#2}\ {+_{#1}}\ {#3}}}
%\newcommand{\iterate}[2]{\ensuremath{{#2}^{\left(#1\right)}}}
%\newcommand{\bexp}[0]{\ensuremath{\text{BExp}}}
%\newcommand{\gexp}[0]{\ensuremath{\text{Exp}}}
%\newcommand{\usg}[0]{\ensuremath{\text{u}}}
%\newcommand{\eval}[0]{\ensuremath{\mathtt{eval}}}
%\newcommand{\sat}[0]{\ensuremath{\mathtt{sat}}}
%\newcommand{\sg}[0]{\ensuremath{\text{s}}}
%\newcommand{\set}[1]{\ensuremath{\left\{#1\right\}}}
%\newcommand{\lbl}[0]{\ensuremath{\text{lbl}}}
%\newcommand{\Real}[0]{\ensuremath{\mathbb{R}}}
%\newcommand{\Nat}[0]{\ensuremath{\mathbb{N}}}
%\newcommand{\letter}[0]{\ensuremath{\left(\text{A-Z\ |\ a-z}\right)}}
%\newcommand{\Atom}[0]{\ensuremath{\text{At}}}
%\newcommand{\GuardedString}[0]{\ensuremath{\text{GS}}}
%\newcommand{\RC}[0]{\ensuremath{\text{RC}}}
%\newcommand{\Low}[0]{\ensuremath{\text{Low}}}
%\newcommand{\Variable}[0]{\ensuremath{\mathscr{V}}}
%\newcommand{\Integer}[0]{\ensuremath{\mathbb{Z}}}
%\newcommand{\alphanumeric}[0]{\ensuremath{\left(\text{A-Z\ |\ a-z\ |\ 0-9}\right)}}
%\newcommand{\alphanumericP}[0]{\ensuremath{\left(\text{A-Z\ |\ a-z\ |\ 0-9\ |\ .\ |\ \_\ |\ \$}\right)}}
%\newcommand{\semantics}[1]{\ensuremath{\llbracket #1\rrbracket}}
%\newcommand{\valuation}[0]{\ensuremath{\Gamma}}
%\newcolumntype{L}{>{$}l<{$}} % math-mode version of "l" column type
%\newcolumntype{R}{>{$}r<{$}} % math-mode version of "r" column type
%\newcolumntype{C}{>{$}c<{$}} % math-mode version of "c" column type
%%\newcommand{\hourglass}[0]{}%{\LARGE\fontspec{Cambria}^^^^231b}
%\newcommand{\timeequiv}[0]{\equiv_{\hourglass}}

\chapter{Side-Channel Repair} % Main chapter title

\label{ChapterGKAT} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{General Idea}
In the following, whenever we write \emph{program}, we mean \emph{non-concurrent program}
The premises of our work are the following:
\begin{itemize}
\item Every program can be linearised using a set of \emph{predication axioms}.
\end{itemize}

\section{Related work and how do we distinguish from them}
\begin{itemize}
\item Ashay Rane: we do not use \emph{cmove} as a primitive instruction, since it \todo{prove this?}may be vulnerable to spectre attacks
\end{itemize}

\section{CTP (Cryptocoding) Axioms, and our solution}
Taken from \cite{cryptocoding}.
\begin{itemize}
\item Compare secrets in constant time.
\begin{itemize}
\item We implement a constant-time comparison function for each type at the LLVM IR. Do note that there are several comparison operations: leq, geq, neq, etc. Ideally, we have a way to implement them at the IR level, but this might not be possible; in other words, there may be the need to leave these as primitive operations that are translated differently for the different architectures. This latter approach has its advantages though: there is room for optimization and we can ensure that it, in fact, gets translated to a sequence of constant time instructions; however, it requires more muscle, i.e., we need to be super careful on how we translate them so that they are, in fact, constant time. 
\end{itemize}
\item Avoid branchings controlled by secret data
\begin{itemize}
\item The suggested solution: 
\begin{quote}
Timing leaks may be mitigated by introducing dummy operations in branches of the program in order to ensure a constant execution time. It is however more reliable to avoid branchings altogether, for example by implementing the conditional operation as a straight-line program. To select between two inputs a and b depending on a selection bit (a la CTSelect). 
\end{quote}
\item We implement predication axioms that allow us to transform control structures into arithmetic expressions using Shannon expansions.
\end{itemize}
\item Avoid table look-ups indexed by secret data
\begin{itemize}
\item The suggested solution: 
\begin{quote}
Replace table look-up with sequences of constant-time logical operations, for example by bitslicing look-ups (as used in NaCl's implementation of AES-CTR, or in Serpent. For AES, constant-time non-bitsliced implementations are also possible, but are much slower. (check blog for resources on how to do this).
\end{quote}
\item The two available options is to somehow implement a rudimentary version of ORAM or make lookups on a set generated by the secret (which should probably be similar to what bit slicing is).
\end{itemize}
\item Avoid secret-dependent loop bounds
\begin{itemize}
\item The suggested solution: 
\begin{quote}
Make sure that all loops are bounded by a constant (or at least a non-secret variable). In particular, make sure, as far as possible, that loop bounds and their potential underflow or overflow are independent of user-controlled input (you may have heard of the Heartbleed bug).
\end{quote}
\item Our solution: each secret has an associated iteration bound (i.e., loops that depend on that secret will be unwinded that number amount of times).
\end{itemize}
\item Prevent compiler interference with security-critical operations (i.e., compilers can mess up your patches)
\begin{itemize}

\item The suggested solution: 
\begin{quote}
Look at the assembly code produced and check that all instructions are there. (This will not be possible for typical application sizes, but should be considered for security-sensitive code.)

Know what optimizations your compiler can do, and carefully consider the effect of each one on security programming patterns. In particular, be careful of optimizations that can remove code or branches, and code that prevents errors which "should be impossible" if the rest of the program is correct.

When possible, consider disabling compiler optimizations that can eliminate or weaken security checks.

Note that such workarounds may not be sufficient and can still be optimized out.
\end{quote}
\item Our solution: we suggest that CTFixes happen as latter as possible in the compilation chain. We can only offer guarantees at the LLVM IR level, the rest is target specific (this is acceptable, since the repair paper works at the same level).
\end{itemize}

\item Prevent confusion between secure and insecure APIs
\item Avoid mixing security and abstraction levels of cryptographic primitives in the same API layer
\item Use unsigned bytes to represent binary data
\begin{quote}
Some languages in the C family have separate signed and unsigned integer types. For C in particular, the signedness of the type char is implementation-defined. This can lead to problematic code.
\end{quote}
\begin{itemize}
\item Their suggestion:
\begin{quote}
In languages with signed and unsigned byte types, implementations should always use the unsigned byte type to represent bytestrings in their APIs.
\end{quote}
\item our solution: LLVM IR does uses both signed and unsigned. We need an axioms to only yield unsigned byte types.
\end{itemize}
\item Clean memory of secret data
\begin{itemize}
\item Our suggestion: although this might take a lot of time, it is a good idea to reset all input secrets and their intermediate operations. 
\end{itemize}
\item Use strong randomness
\begin{itemize}
\item Our suggestion: we cannot really enforce this. We assume it. (TBH I dunno how does randomness work on the LLVM IR).
\end{itemize}
\item Always typecast shifted values\todo{read blog}.
\end{itemize}

Do note also the following:
\begin{itemize}
\item Casting operations at higher level may be dangerous: they might introduce branching at the lower level for some architectures (there is an example where a \_Bool is casted into an uint\_32 in the blog.
\end{itemize}
\section{Formalisation}
We use Guarded Kleene Algebra with Tests (GKAT) \cite{GKAT} to define our transformation rules. the GKAT syntax is as follows:
\newline
\begin{minipage}{0.5\textwidth}
\begin{align*}
\begin{tabular}{RCLL}
\multicolumn{4}{L}{b,c,d, \in \bexp::=} \\
  &    |   &  0   		&  \textbf{False}   \\
  &    |   &   1   		&   \textbf{True}   \\
  &    |   &    t\in T  		&   t  \\
  &    |   &    b \cdot c  	&  b \ \textbf{and}\ c   \\
  &    |   &    b+c  		&   b \ \textbf{or}\ c   \\
  &    |   &    \bar{b}  	& \textbf{not}\ b
\end{tabular}
\end{align*}
\end{minipage}%
\begin{minipage}{.5\textwidth}
   \begin{align*}
\begin{tabular}{RCLL}
\multicolumn{4}{L}{e,f,g, \in \gexp::=} \\
  &    |   &  p \in \Sigma  		&  \textbf{do } p \\
  &    |   &   b \in \bexp   		&   \textbf{assert } b \\
  &    |   &    e \cdot f  			&  e{;}f   \\
  &    |   &   \branch{b}{f}{g} 	&   \textbf{if }b \textbf{ then }f\textbf{ else }g   \\
  &    |   &    \iterate{b}{e} 		& \textbf{while }b\textbf{ do }e
\end{tabular}
\end{align*}
\end{minipage}
\paragraph{}
We take a layered approach to constant time programming (CTP); initially, we consider actions $a\in \Sigma$ to be abstract (i.e., only symbols), then, we give semantics to actions by mapping them to a set of instructions in LLVM IR. This layered approach allows us to exclusively focus on program structure, and how branching and iteration could introduce side channels.

\subsection{Language-Based Semantics CTP}
The language-based semantics of a GKAT expression $e$ corresponds to a language of \emph{guarded strings} \cite{GKAT}. Informally, a guarded string is an interleaved sequence of \emph{(logical) atoms} and actions, which model how actions change the state of the system. Informally, an \emph{atom} is a valuation of all tests in the set of tests $T$ (e.g., if $T=\{t_1,t_2\}$, the expressions  $\overline{t_1}\land \overline{t_2}$, $\overline{t_1}\land {t_2}$, $t_1\land \overline{t_2}$, and $t_1\land {t_2}$ are the atoms). Formally, an atom is a non-zero minimal element in the free boolean algebra in $T$ \cite{KAT}. We denote atoms by $\alpha, \beta,$ and $\gamma$, and the set of atoms by $\Atom$. The formal definition of a guarded string is as follows.

\begin{definition}[Guarded String]
Given a set of actions $\Sigma$ and a set of tests $T$, a \emph{guarded string} $g$ is an element of the set $\GuardedString := \Atom \cdot \left(\Sigma\cdot \Atom\right)^{*}$. 
\end{definition}

\todo[inline]{Here is where you explain what the semantics of GKAT expressions are in terms of guarded strings, and you say that infinite loops yield an empty language, which is super weird, right?}

\begin{definition}[Resource Metrics and Resource Consumption]
A \emph{resource metric} is a map $m\colon \GuardedString \rightarrow \Sigma \rightarrow \Real^{+}$. Given a resource metric $m$ and a guarded string $g$, the value of $m(g)(a)$ is the {resource consumption for the action $a$ after executing all the actions in $g$}. The \emph{resource consumption} of $g$, denoted $\RC(g)$, is the accumulated resource consumption of its actions; formally,
\begin{align}
\RC(g)&\triangleq 
\begin{cases}
0, &\quad \text{if $g \in\Atom$;}\\
\RC(h) + m(h)(a),&\quad \text{if $g=h \cdot a\cdot \alpha $;}\\
\end{cases}
\end{align}

{\color{red}Henceforth, we will assume that resource metrics are history-independent, i.e., resource consumption is independent of previous actions or initial conditions, meaning that resource metrics are instead maps of type $\Sigma \rightarrow \Real^{+}$.  }
\todo[inline]{Are there relevant cases where this is not true? Answer: actually, the memory footprint may probably be one of these cases (more precisely, memory footprint should also consider the interaction environment in shared caches... it can get really complicated if we want to model everything...)}

\end{definition}

\begin{definition}[Weak Constant Time]
Given a language of guarded strings $L\subseteq \GuardedString$, we say that $L$ has \emph{weak constant time} if and only if, for all $g_1, g_2 \in L$, $\RC(g_1)=\RC(g_2)$. 
\end{definition}

We also define a strong notion of constant time to study more modular attackers.
\begin{definition}[Strong Constant Time]
Given a language of guarded strings $L\subseteq \GuardedString$, we say that two guarded strings $g_1, g_2 \in L$ are \emph{strong constant time equivalent}, denoted $g_1 \timeequiv g_2$, if and only if,
\begin{align}
g_1 \timeequiv g_2 \triangleq \begin{cases}
\textbf{true}, &\quad \text{if $g_1\in \Atom$ and $g_2\in \Atom$,}\\
g_1' \timeequiv g_2' \land m(g'_1)(a_1)=m(g'_2)(a_2),&\quad \text{if $g_i=g_i' \cdot a_i\cdot \alpha_i $ for $i=1,2$; }
\end{cases}
\end{align}
We say that  $L$ has \emph{strong constant time} if and only if, for all $g_1, g_2 \in L$, $g_1\timeequiv g_2$.
\end{definition}

To obtain the notion of constant time that is used for security analysis, we need to match traces that are only equal on their public variables. Atoms themselves may match even when public values are different (e.g. if $p$ is public, the test $p\leq 128$ is satisfied by any public value below 128); thus, we need to make the state of public variables explicit. For such purposes, let $\Variable$ be the set of variables, and let $\semantics{\Variable}$ be the set of valuation functions which map variables to values; we override the definition of guarded strings so that the set of guarded strings is now generated by the grammar
\begin{align}
\GuardedString := \left(\semantics{\Variable}\times\Atom\right) \cdot \left(\Sigma\cdot \left(\semantics{\Variable}\times\Atom\right)\right)^{*}.
\end{align}
Thus, guarded strings now satisfy either the pattern $(\valuation,\alpha)$ or the pattern $(\valuation,\alpha)\cdot a\cdot h$, where $\valuation$ is a valuation of the variables, $\alpha$ is an atom and $h$ is a guarded string.

\begin{remark}
{If the domains of variables are finite, this formulation reduces to the original formulation as follows: for each variable $p$ and each of its possible values $v$, we include the proposition $p=v$ in the set of tests.}
\end{remark}
\begin{definition}[Public Equality]
Whenever two valuations $\valuation_1$ and $\valuation_2$ are equal on their public variables, we denote it by $\valuation_1=_p\valuation_2$. Two guarded strings $g_1$ and $g_2$ are equal on their public variables, denoted $g_1=_p g_2$, if and only if their \emph{initial} valuations are equal on public variables. 
\end{definition}
Depending on the attacker model, we might choose one of the following definitions to suit our needs best:
\begin{definition}[Secure Weak Constant Time]
Given a language of guarded strings $L\subseteq \GuardedString$, we say that $L$ has \emph{secure weak constant time} guarantees if and only if, for all $g_1, g_2 \in L:$
\begin{align}
g_1=_p g_2\Rightarrow\RC(g_1)=\RC(g_2).
\end{align}
\end{definition}

\begin{definition}[Secure Strong Constant Time]
Given a language of guarded strings $L\subseteq \GuardedString$, we say that $L$ has \emph{secure strong constant time} guarantees if and only if, for all $g_1, g_2 \in L:$
\begin{align}
g_1=_p g_2\Rightarrow g_1\timeequiv g_2.
\end{align}
\end{definition}

\section{The IMP Language}
We explore the simple imperative programming language with variable assignments and boolean expressions from \cite{GKAT}: IMP; the language is defined as follows:
\begin{align*}
{\small
\begin{tabular}{L RL}
\text{-- arithmetic expressions:} & a\in \mathscr{A}\!\!\!\!\!\! &::= x\in \Variable\ |\ n \in \Nat\ |\ a_1+a_2\ |\ a_1-a_2\ |\ a_1\times a_2\\
\text{-- boolean expressions:} & b\in \mathscr{B}\!\!\!\!\!\! &::= \textbf{false}\ |\ \textbf{true}\ |\ a_1<a_2\ |\ \textbf{not } b\ |\ b_1 \textbf{ and } b_2\ |\ b_1 \textbf{ or } b_2\\
\text{-- commands:} & c\in \mathscr{C}\!\!\!\!\!\! &::= \textbf{skip}\ |\ x:=a\ |\ c_1;c_2\ |\ \textbf{if }b\text{ then }c_1\text{ else }c_2\ |\ \textbf{while } b\textbf{ do }c
\end{tabular}
}
\end{align*}

As stated in \cite{GKAT}, this language can be modelled in GKAT using actions for assignments and primitive tests for comparisons as follows:
\begin{align}
\Sigma=\set{x:=a\ |\ x\in \Variable, a\in \mathscr{A}}, \quad T=\set{a_1 < a_2\ |\ a_1,a_2\in \mathscr{A}}.
\end{align}
Following \cite{GKAT}, we interpret GKAT expressions over the space of variable assignments $\semantics{\Variable}\triangleq\Variable \rightarrow\Nat$:
\begin{align*}
\eval(x:=a)&\triangleq \set{(\sigma, \sigma[x:=n])\ |\  \sigma \in \semantics{\Variable}, n=\mathscr{A}\semantics{a}_\sigma},\\
\sigma[x:=n]&\triangleq \uplambda y \ldotp 
	\begin{cases}
		n, \quad &\text{if $y=x$};\\
		\sigma(y), \quad&\text{otherwise},
	\end{cases}\\
\sat(a_1<a_2)&\triangleq \set{\sigma \in \semantics{\Variable}\ |\ \mathscr{A}\semantics{a_1}_{\sigma} < \mathscr{A}\semantics{a_2}_{\sigma}},
\end{align*}
%where $\mathscr{A}\semantics{a}_\sigma\colon \semantics{\Variable}\rightarrow \Real_\perp$ denotes arithmetic evaluation of the expression $a$ in the context of $\sigma$.
where $\mathscr{A}\semantics{a}_\sigma$ denotes the arithmetic evaluation of $a$ in the context of $\sigma$. Finally, sequential composition, conditionals and while loops are modelled by their GKAT counterparts, and $\mathbf{skip}$ is modelled by 1.


\section{Memory Footprint for the IMP Language}
A memory footprint considers how variables are contiguously allocated in memory. To capture the notion of a memory footprint, we are going to give a dimension to variables so they now work as finite vectors indexed by integers.  Given a variable $\vec{x}\in \Variable$ and an arithmetic expression $a \in \mathscr{A}$, the expression $\vec{x}[a]$ refers to the value stored in $\vec{x}$ at position $a$.

This treatment of variables as vectors not change the expressivity of the IMP language, and it is purely to address the fact that, for several computer architectures, when we read a memory location (e.g, $\vec{x}[a]$), its contiguous locations are also loaded into the cache (e.g., $\vec{x}[a+1]$ to $\vec{x}[a+k-1]$, where $k$ is the cache line size).

\subsection{Secure Constant Memory}
Now that actions have a more concrete semantics, we can describe how we expect a program in IMP to interact with cache memory. We follow \cite{Chattopadhyay} and describe caches using three main parameters: cache line size (CLS) in bytes, the number of cache sets (CS) and an associativity and replacement policy (P). 

Our main challenge in defining a resource consumption function to model how actions affect the state of the cache stems from the case where caches are shared by different processes. If we want our transformed programs to be resilient to attacks like \textsc{Flush+Reload}, then 

\section{The IMP Language with Division}
We modify the simple imperative programming language with variable assignments and boolean expressions from \cite{GKAT} --IMP-- so that it includes division; the language is defined as follows:
\begin{align*}
{\small
\begin{tabular}{R RL}
\text{arithmetic expressions} & a\in \mathscr{A}\!\!\!\!\!\! &::= x\in \Variable\ |\ n \in \Real_\perp\ |\ a_1+a_2\ |\ a_1-a_2\ |\ a_1\times a_2\ |\ a_1 \div a_2\\
\text{boolean expressions} & b\in \mathscr{B}\!\!\!\!\!\! &::= \textbf{false}\ |\ \textbf{true}\ |\ a_1<a_2\ |\ a_1-a_2\ |\ \textbf{not } b\ |\ b_1 \textbf{ and } b_2\ |\ b_1 \textbf{ or } b_2\\
\text{commands} & c\in \mathscr{C}\!\!\!\!\!\! &::= \textbf{skip}\ |\ x:=a\ |\ c_1;c_2\ |\ \textbf{if }b\text{ then }c_1\text{ else }c_2\ |\ \textbf{while } b\textbf{ do }c
\end{tabular}
}
\end{align*}
where $\Real_\perp=\Real \uplus \{\perp\}$, and $\perp$ is a symbol to denote \emph{not-a-number} (NaN).

As stated in \cite{GKAT}, this language can be modelled in GKAT using actions for assignments and primitive tests for comparisons as follows:
\begin{align}
\Sigma=\set{x:=a\ |\ x\in \Variable, a\in \mathscr{A}}, \quad T=\set{a_1 < a_2\ |\ a_1,a_2\in \mathscr{A}}.
\end{align}
Following \cite{GKAT}, we interpret GKAT expressions over the space of variable assignments $\semantics{\Variable}\triangleq\Variable \rightarrow\Real_\perp$:
\begin{align*}
\eval(x:=a)&\triangleq \set{(\sigma, \sigma[x:=n])\ |\  \sigma \in \semantics{\Variable}, n=\mathscr{A}\semantics{a}_\sigma},\\
\sigma[x:=n]&\triangleq \uplambda y \ldotp 
	\begin{cases}
		n, \quad &\text{if $y=x$};\\
		\sigma(y), \quad&\text{otherwise},
	\end{cases}\\
\sat(a_1<a_2)&\triangleq \set{\sigma \in \semantics{\Variable}\ |\ \mathscr{A}\semantics{a_1}_{\sigma} < \mathscr{A}\semantics{a_2}_{\sigma}},
\end{align*}
%where $\mathscr{A}\semantics{a}_\sigma\colon \semantics{\Variable}\rightarrow \Real_\perp$ denotes arithmetic evaluation of the expression $a$ in the context of $\sigma$.
where $\mathscr{A}\semantics{a}_\sigma$ denotes the arithmetic evaluation of $a$ in the context of $\sigma$. Finally, sequential composition, conditionals and while loops are modelled by their GKAT counterparts, and $\mathbf{skip}$ is modelled by 1.



\subsection{Examples of Side Channel Attacks}

\subsection{Transformations Rules for CTP in IMP}
%The most important transformation for constant time are predication and loop unwinding. 
Branch balancing is a technique to enforce CTP at the language level. This technique adds dummy instructions to shorter branches so that both branches have the same resource consumption. We capture this notion with the following repair rule.
\begin{definition}[Branch Balancing]
\begin{align*}
\branch{b}{(x:=a_1)}{1} \leadsto \branch{b}{(x:=a_1)}{(x:=x)}
\end{align*}
\end{definition}
To balance branches, we want an instruction that has the same resource consumption as $x:=a$, but acts as an identity on $x$, hence the choice for $x:=x$.  To avoid undefined behaviour, we assume that all variables are initialised by default with a value of 0 so the assignment $x:=x$ is always well defined. 
%\todo[inline]{Maybe we can define at the theoretical level an instruction $\textbf{noOp}(:=)$?}

While branch balancing may seem like a sound solution, the compiler may remove all dummy instructions inserted since it considers them to be no-ops, taking us back to an unbalanced program at the binary level. To overcome this limitation, we rely on the correspondence between program structure and arithmetic expressions, captured by the following repair rule.
\begin{definition}[Predication]
\begin{align*}
\branch{b}{(x:=a_1)}{(x:=a_2)} \leadsto x:=b\otimes a_1+(\textbf{not }b)\otimes a_2
\end{align*}
where $\otimes$ is multiplication, but it interprets the boolean condition as 0 or 1 depending on whether the condition evaluates to $\textbf{false}$ or $\textbf{true}$, respectively. 
%Strict typing
%\begin{align*}
%\branch{b}{(x:=a_1)}{(x:=a_2)} \leadsto \left(\branch{b}{(m:=1)}{(m:=0)}\right)\cdot(x:=m\times a_1+(1-m)\times a_2)
%\end{align*}
\end{definition}
The predication rule forces the evaluation of all terms in both branches, so it is more resource intensive than branch balancing; however, predication addresses two of our objectives: one is to prevent the compiler from removing dummy assignments introduced during branch balancing, and the second is to remove branches that might be vulnerable to spectre attacks.

Loops have two problems: in general, they are both vulnerable to spectre attacks and timing side-channel attacks. The former vulnerability is due to the branching implicitly introduced by the loop's guard, and the latter is due to the variable number of executions of the loop's body. Both of these vulnerabilities can be addressed by a combination of branch balancing, predication and the following transformation rule.
%{\color{lightgray}
%\begin{definition}[Delay Termination]
%if $s$ is a secret, then we need a public constant $p$  to transform the loop so it becomes secret-independent
%\begin{align*}
%\iterate{x<s}{g} \leadsto \iterate{x<p}{\left(\branch{(x<s)}{g}{1}\right)}
%\end{align*}
%\end{definition}
%Unfortunately, this rule is still vulnerable to spectre attacks introduced by the verification loop condition $x<p$. We want to eliminate the loop altogether.}
\begin{definition}[$k$-Truncation]
%Loop unwinding is an original axiom from GKAT, represented by the equivalence
%\begin{align*}
%\iterate{b}{e} \equiv \branch{b}{(e\cdot\iterate{b}{e})}{1} 
%\end{align*}
%\begin{align*}
%\branch{b}{(e\cdot\iterate{b}{e})}{1} \equiv \branch{b}{(e\cdot(\branch{b}{(e\cdot\iterate{b}{e})}{1} ))}{1} \\
%\branch{b}{(e\cdot\iterate{b}{e})}{1} \equiv \branch{b}{(e\cdot(\branch{b}{(e\cdot\iterate{b}{e})}{1} ))}{1} \\
%\end{align*}
To $k$-truncate a loop means that we transform $\iterate{b}{e}$ into a sequence of $k$ conditional statements by unwinding the loop as follows
%\begin{align*}
%\iterate{x<n}{\left(g\cdot(x:=x+1)\right)} \leadsto \underbrace{\branch{(x<n)}{\left(g\cdot(x:=x+1)\right)}{1}}_\text{$k$ times},
%\end{align*}
%\begin{align*}
%\iterate{x<n}{(x:=x+a)} \equiv \branch{(x<n)}{\left((x:=x+a)\cdot \iterate{x<n}{(x:=x+a)}\right)}{1} 
%\end{align*}
\begin{align*}
\iterate{b}{e} \leadsto \underbrace{\left(\branch{b}{e}{1}\right)\cdot\left(\branch{b}{e}{1}\right)\ldots\left(\branch{b}{e}{1}\right)}_\text{$k$ times}
\end{align*}
An equivalence relation between $\iterate{b}{e}$ and its $k$-truncation can be obtained if $k$ is a public over-approximation of the (secret-dependent) loop bound of $\iterate{b}{e}$.

Compilers normally avoid this type of unwinding when combined with predication, because it would cause programs to slow down. However, in the context of CTP, this type of delays are desirable since they make loops safe in terms of resource consumption, and the lack of branching eliminates spectre vulnerabilities.

\todo[inline]{The programmer should tell us somehow how many times we unwind each loop that depends on a secret. FaCT forces loops to be of the form ``for x from e to e'' to fix iteration increments so they know how to unwind.}
\end{definition}

\section{Taint Analysis}
\todo[inline]{Here is an interesting problem: if we have a non-security critical section (e.g., a loop that does not depend on secret) inside a section we are applying linearisation, do we need to linearise it? Probably not! The problem is that this is not compatible with our current implementation, because the current implementation linearises everything. If we introduce breakpoints we can allow loops in the branches.}

A naive definition of Taint analysis is the following: a variable is tainted if an only if, from belongs to the transitive closure of the small-step taint procedure, which marks all uses of a tainted variable as tainted. There is no untainting. We assume that, after basic code optimisations have taken place, all uses of a variable are productive an monotonous in the security hierarchy (i.e., expressions are not constant W.R.T secret inputs, and they do not inherently lose their security label). Maybe we could empower the language with annotations that override whatever taint analysis infers?

\section{The Enforcement Algorithm}
We present a $k$-step \todo{Resolve $k$} 
enforcement algorithm that enforces CTP techniques at the level of LLVM IR (compiler level) to eliminate timing side channels introduced by the use of branching and loops. 

We implement these algorithms as LLVM passes, so it is useful to understand how code is organised in LLVM.

\subsection{Premises Behind the Enforcement Algorithm}
\begin{itemize}
\item Programmers need not worry about CTP at the language level, but rather delegate as much work as possible to the compiler. The compiler may ask for information about loop bounds and about which fields are secret (these can be annotations provided by the programmer). When compiling with the right flags, the compiler may optimise the code using standard optimisations, but must ultimately enforce CTP.
\item The sequential composition of CTP programs is CTP.  This is better understood when working with GKAT expressions: if all \emph{actions} are CTP, then their sequential composition is CTP. Even if actions are CTP, GKAT \emph{expressions} are not necessarily CTP; as we know, branching and iteration do not intrinsically satisfy CTP.
\item The attacker model is a rather strong in the sense that it can measure resource consumption of prefix executions and not only total executions, which is equivalent to an attacker that can measure the resource consumption of each individual action.
\item The enforcement algorithm is sound: a repaired version $R[P]$ of program $P$ is functionally equivalent to $P$ in terms of input and output, but $R[P]$ satisfies the secure constant time property.
\item The enforcement algorithm is probably not transparent: if a program $P$ satisfies CTP, its repaired version $R[P]$ will also satisfy CTP, but $R[P]$ and $P$ may differ in terms of resource consumption, with $R[P]$ requiring more time to execute than $P$. \todo[inline]{This is just my intuition, but I would like to get empirical evidence.}
\end{itemize}

\subsection{An LLVM Primer}
LLVM IR is a strongly typed language. We interpret an LLVM IR program as a directed graph of {basic blocks}. A \emph{basic block} (BB) is a finite sequence of non-terminating instructions followed by a single terminating instruction. In this work, a \emph{terminating} instruction is either: 1) a return instruction, which terminates the program, 2) an unconditional transition to a single BB, or 3) a conditional branching where, depending on the branching condition, there is a transition to one of two BBs.

Without loss of generality, values used inside BBs are only accessible to the BB where they are declared (this can be enforced with the \texttt{opt} optimisation flag \texttt{-reg2mem}).  We use \emph{load} and \emph{store} instructions to allow cross BB communication .

\todo[inline]{A figure/example may help?}

 that uses single-static assignment for virtual registers and has memory read/write operations to enable communication between 

A function in LLVM consists of a header BB, and, without loss of generality, a single exit BB. 

\todo[inline]{Dominator/Postdominator}
\subsection{The \texttt{Linearise} Algorithm}
We start with a function $F$ that has a single entry block and a single exit block. In a nutshell, the algorithm advances from the entry block until it finds a branch or the exit block. In the case of a branch  $\texttt{br} c A B$, the algorithm recursively linearises the branches starting in blocks $A$ and $B$ until their postdominator $\texttt{postDom}(A,B)$, and then proceeds to continue linearisation towards the exit block.

\todo[inline]{Why don't we try to describe the algorithm considering loops? It's going to be a fun exercise.}

\begin{algorithm}
    \caption{Linearisation algorithm}
    \label{Linearisation}
    \begin{algorithmic}[1] % The number tells where the line numbering should start
        \Procedure{Linearise}{$\texttt{IN},\texttt{OUT},\Delta$} 
            \If{\texttt{IN}==\texttt{OUT}}
            	\State \Return $[\texttt{IN}]$
	   \Else
	   	\State $t \gets \texttt{terminator}(\texttt{IN})$
		  \If{$t$ is \texttt{jmp NXT}}\Comment{Unconditional Jump}
		      \State  \Return $(\texttt{IN}:$\texttt{ Linearise}({$\texttt{NXT},\texttt{OUT},\Delta$}))\ \Comment{Continue from $\texttt{NXT}$}
		  \ElsIf{$t$ is \texttt{br C L R}}\Comment{Conditional Branching on Secret}
		  	\State $\texttt{PD} \gets \texttt{PostDominator}(\texttt{L},\texttt{R})$
			\State $\texttt{L'}\gets \texttt{Linearise}(\texttt{L},\texttt{PD})$
			\State $\texttt{R'}\gets \texttt{Linearise}(\texttt{R},\texttt{PD})$
			\State $\texttt{M} \gets \texttt{Predication}(\texttt{C},\texttt{L'},\texttt{R'})$
			 \State  \Return $(\texttt{IN}: \texttt{M}:$\texttt{ Linearise}({$\texttt{PD},\texttt{OUT},\Delta$}))\ \Comment{Continue from $\texttt{PD}$}
		  \EndIf
            \EndIf
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\begin{algorithm}
    \caption{Euclid's algorithm}
    \label{euclid}
    \begin{algorithmic}[1] % The number tells where the line numbering should start
        \Procedure{Euclid}{$a,b$} \Comment{The g.c.d. of a and b}
            \State $r\gets a \bmod b$
            \While{$r\not=0$} \Comment{We have the answer if r is 0}
                \State $a \gets b$
                \State $b \gets r$
                \State $r \gets a \bmod b$
            \EndWhile\label{euclidendwhile}
            \State \textbf{return} $b$\Comment{The gcd is b}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\subsection{A Premise for Efficient Repaired Code}
The premise behind why our algorithm could compete against other algorithms that protect against spectre attacks is that fencing, the SoTA defence against Spectre attacks, prevents speculative execution (i.e., puts a halt in instruction pipeling) while our transformation promotes safe pipelining.

\subsection{Enforcing Safe Behaviour}
\todo[inline]{I originally thought that this section should be part of the GKAT rules, but after some consideration, if we were to assume that sanitisation is part of the actions (i.e. is a part of CTP practices), then this section becomes largely irrelevant for the theory. However, since LLVM can have problems when accessing arrays or dividing by zero, this should be mentioned in the LLVM section, probably.}
Dividing by zero or accessing a position outside of an array are two examples of computations that may raise exceptions during runtime. These exceptions can be mitigated by sanitising the inputs to these functions. This sanitisation is often responsibility of the programmer, who uses conditionals to ensure that the inputs are safe to use. Since our repair rules remove conditionals by forcing the execution of both branch paths, they may introduce runtime exception that were not present in the original program. This is a well-known problem when using predication (see \cite{Rane}), and to overcome it, we need to shift sanitisation of inputs to the compiler or to the architecture. 

Consider the program $\textbf{if }b \textbf{ then } y:=z/x \textbf{ else skip}$. The repair rules would transform it into the program $y:=b\otimes (z/x)+(\textbf{not }b)\otimes y$. If $b$ is a condition that rules out whether $x$ is not equal to zero, we might run into problems should we evaluate $z/x$ in the repaired program. If $\otimes$ is to follow CTP practices, its execution time must not vary on the value of its (secret) input parameters, so early termination by checking if any of the parameters is zero is not allowed. If both parameters are fully evaluated before applying multiplication, we can be certain that the expression $z/x$ is going to be evaluated, even if $x$ is equal to 0. %Fortunately, the value of $z/x$ is guarded by $(x\neq 0)$, 
To avoid raising an exception at runtime, we enforce input sanitisation at compiler level by using a variable $x_\texttt{div}$ to assign a default safe value (e.g., 1) to the parameter of the division function in case the original variable is unsafe, yielding the following repaired program
\begin{align}
x_\texttt{div}:= (x\neq 0)\otimes x+(x=0)\otimes 1\ ;\ y:=b\otimes (z/x_\texttt{div})+(\textbf{not }b)\otimes y\ .
\end{align}
Since we evaluate $z/x_\texttt{div}$ instead of $z/x$ in the repaired program, the repaired program is also safe if the original program was safe. We remark that the choice of the default safe value should be irrelevant in the context of CTP because, if the division operation also follows CTP practices, then it should not matter which values we choose as long as they do not break the functionality of the program. 

Now, consider the program $\textbf{if }b \textbf{ then } y:=A[x] \textbf{ else skip}$. Similarly to the previous example, if we repair this program naively, we obtain the program $y:=b\otimes A[x]+(\textbf{not }b)\otimes y$ which might introduce runtime exceptions should $A[x]$ be executed when $x$ is greater than the size of $A$. We can sanitise the input by 
\[x_\texttt{idx}:= (x<\textbf{size}(A))\otimes x;\ y:=b\otimes A[x_\texttt{idx}]+(\textbf{not }b)\otimes y\ ,
\]
\todo[inline]{OR}
\[x_\texttt{idx}:= x \textbf{ mod }(\textbf{size}(A));\ y:=b\otimes A[x_\texttt{idx}]+(\textbf{not }b)\otimes y\ ,
\]
to avoid undesired side effects.
\todo[inline]{I have the hunch that substituting the expression $A[x]$ for $ A[x\textbf{ mod }(\textbf{size}(A))]$ might leak via memory SC that the secret is a multiple of the array index that corresponds to $x\textbf{ mod }(\textbf{size}(A))$. However, this substitution for $A[0]$ also leaks that the secret is greater than the size of the array. Now, using a secret as an index should be frowned upon by CTP guidelines, but do we want to define the problem away? probably not. What this is missing is the memory SC mitigation, and any of the options above should be valid.}

\subsection{A GKAT to Correctly Unwind Basic Block Loops}
\todo[inline]{The objective of this section is to provide the background theory to prove that the loop transformation that we use in the CFG corresponds to an unwinding transformation of GKAT iteration expressions. For that, we show that the CFG of an LLVM IR program models a normal GKAT coalgebra. If that is the case, then, from a normal GKAT coalgebra, we can use Kleene's theorem for GKAT to obtain a GKAT expression that models the program. Once we have the GKAT expression, we can unwind loops using $k$-truncation. Somehow, this should be equivalent to unwinding a loop in the CFG (even if the loop has multiple exit points). If I am not mistaken, we want to identify two blocks: the header block and the merging block of the loop. The header is unique by definition, but the merging block is the postdominator of all exiting blocks in the loops, and that is what we will end up iterating using GKAT iteration.
}

The Control Flow Graph (CFG) of LLVM IR consists of Basic Blocks (BBs). Each BB has a single entry point and a single exit point, the latter represented by a \emph{terminator instruction}. Let us consider only two types of termination instructions for BBs:
\begin{enumerate}
\item $\texttt{return }v$, which ends the current execution and returns a value $v$; and
\item $\texttt{branch $\alpha:$ $BB_1$ ; $BB_2$}$, which states that we should continue execution from $BB_1$ if the condition $\alpha$ is valid, or continue execution from $BB_2$ otherwise.
\end{enumerate}
\todo[inline]{The $\texttt{branch}$ instruction can be generalised to a $\texttt{switch}$ instruction, but we work with binary branching since it is possible to express a switch associating on the right, so we go o a basic block on the else branch that continues resolving the cases of the switch following the classical \texttt{switch $g_i:c_i$ $\equiv$ if $g_1$ then $c_1$ elseif $g_2$ then $c_2$ elseif...} equivalence that most decent programming languages have (which is why I never use switches in C++, since they are not equivalent).}
Let us consider a GKAT where the set of actions $\Sigma$ is the set of BBs and the tests are the conditions used in \texttt{branch} termination instructions.



%\begin{definition}[Loop unwinding]
%%From \cite{GKAT}
%%\begin{align*}
%%\iterate{b}{e} \equiv \branch{b}{(e\cdot \iterate{b}{e})}{1}
%%\end{align*}
%%The programmer should tell us somehow how many times we unwind each loop that depends on a secret. A different version
%\begin{align*}
%\iterate{x<n}{(x:=x+a)} \equiv \branch{(x<n)}{\left((x:=x+a)\cdot \iterate{x<n}{(x:=x+a)}\right)}{1} 
%\end{align*}
%\todo[inline]{The programmer should tell us somehow how many times we unwind each loop that depends on a secret. FaCT forces loops to be of the form ``for x from e to e'' to fix iteration increments so they know how to unwind.}
%\end{definition}



\subsection{Types}
For our first LLVM IR sublanguage, we support the following types:
\begin{itemize}
\item Void type, which cannot be assigned to variables.
\item Integer types of the form $i_N$ where $N\in [1..2^{23}-1]$.
\end{itemize}
An element of type $i_N$ is a vector of $N$ bits; consequently, the type $i_N$ is populated by maps of the form $N\rightarrow 2$\todo{Set Notation}. There are two standard interpretations for $x\colon i_N$, an \emph{unsigned} interpretation $\usg\colon i_N\rightarrow \mathbb{N}$, where 
\begin{align}
\usg(x)= \sum_{n=0}^{N-1} x(n)\times2^{x(n)},
\end{align}
and a \emph{signed} interpretation $\sg\colon i_N\rightarrow \mathbb{Z}$, where
\begin{align}
\sg(x)= 
\begin{cases}
\ \ \ \ \sum_{n=1}^{N-1} x(n)\times2^{x(n)},\quad &\text{if $x(0)=0$};\\
-\sum_{n=1}^{N-1} x(n)\times2^{x(n)},\quad &\text{if $x(0)=1$}.
\end{cases}
\end{align}
In other words, the first bit $x(0)$ determines whether $x$ represents a positive or a negative number under the signed representation.

For the set of instructions we need to introduce the notion of variables and assignments. The set of \emph{variables} $v$ is generated by the regular expression
\begin{align}
v::= (@\ |\ \%)\cdot\letter\cdot\alphanumericP^{*}.
\end{align}
A \emph{variable assignment} is an instruction of the form $v:=e$, where $e$ is a \emph{non-void function} or an \emph{arithmetic expression}. Arithmetic expressions are 
\begin{itemize}
\item Language  
\item Arithmetic operations that use division.
\end{itemize}
\subsection{Instructions} 
\todo[inline]{Overflows}

\subsection{Central idea}
The main theoretical idea of our work is\todo{what is it?}
   %-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Subsection 1}

Nunc posuere quam at lectus tristique eu ultrices augue venenatis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Aliquam erat volutpat. Vivamus sodales tortor eget quam adipiscing in vulputate ante ullamcorper. Sed eros ante, lacinia et sollicitudin et, aliquam sit amet augue. In hac habitasse platea dictumst.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Subsection 2}
Morbi rutrum odio eget arcu adipiscing sodales. Aenean et purus a est pulvinar pellentesque. Cras in elit neque, quis varius elit. Phasellus fringilla, nibh eu tempus venenatis, dolor elit posuere quam, quis adipiscing urna leo nec orci. Sed nec nulla auctor odio aliquet consequat. Ut nec nulla in ante ullamcorper aliquam at sed dolor. Phasellus fermentum magna in augue gravida cursus. Cras sed pretium lorem. Pellentesque eget ornare odio. Proin accumsan, massa viverra cursus pharetra, ipsum nisi lobortis velit, a malesuada dolor lorem eu neque.

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Main Section 2}

Sed ullamcorper quam eu nisl interdum at interdum enim egestas. Aliquam placerat justo sed lectus lobortis ut porta nisl porttitor. Vestibulum mi dolor, lacinia molestie gravida at, tempus vitae ligula. Donec eget quam sapien, in viverra eros. Donec pellentesque justo a massa fringilla non vestibulum metus vestibulum. Vestibulum in orci quis felis tempor lacinia. Vivamus ornare ultrices facilisis. Ut hendrerit volutpat vulputate. Morbi condimentum venenatis augue, id porta ipsum vulputate in. Curabitur luctus tempus justo. Vestibulum risus lectus, adipiscing nec condimentum quis, condimentum nec nisl. Aliquam dictum sagittis velit sed iaculis. Morbi tristique augue sit amet nulla pulvinar id facilisis ligula mollis. Nam elit libero, tincidunt ut aliquam at, molestie in quam. Aenean rhoncus vehicula hendrerit.