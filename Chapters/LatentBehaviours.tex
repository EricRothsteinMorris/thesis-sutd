%!TEX root = ../main.tex
% Chapter Template


\chapter{Latent-Behaviour Analysis, Coalgebraically} % Main chapter title
\label{ch:LatentBehaviours} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\todo[inline]{Find a suitable quote?}
\begin{quote} 
%If you only do what you can do, you will never be more than what you are now.
"As you adequately put, the problem is choice. But we already know what you are going to do, don't we?" -- The Architect.
\end{quote} 

\section{Introduction}
\todo[inline]{Give an interesting motivational example: What is the notion of latent behaviour? Why do we care about them? How is it useful to study them?}
The objective of this section is to explain the commutative diagram presented in Figure~\ref{fig:TheArrow}. This diagram, which we refer to as ``The Arrow of Latent Behaviours,'' illustrates how spatial and behavioural transformations affect the behaviour of an $F$-coalgebra $(X,c)$ by changing the behaviour map from $!_c$ to $!_{b\circ c\circ m}$. 

\begin{figure}[h]
        \centering
        \begin{tikzcd}[column sep=1.75cm, row sep=1cm]
            &\sigma F
                \arrow[dr,swap,"\omega"']
            &
            \\ 
            X  
                \arrow[dd,"c"] 
            & X
                \arrow[l, swap, "m"]
                \arrow[u, "!_{c}"]
                \arrow[r,dotted, swap, "!_{b\circ c\circ m}"]
            &\sigma F 
                %\arrow[dd, "\simeq","\omega"']
                \arrow[dd, "1"]
                \arrow[dr, "\textbf{id}"]
            \\
            &&&\sigma(F)
            \\
            F(X)     
                \arrow[r, swap, "b"]
            &F(X)
                \arrow[d, swap, "F(!_{c})"]
                \arrow[r, dotted, "F(!_{b\circ c\circ m})"] 
            &
            F(\sigma F)
                %\arrow[ur, swap, "\omega^{-1}"]
                \arrow[ur, swap, "1^{-1}"]
            \\
            &F(\sigma F)
                \arrow[ru, swap, "F(\omega)"]
            &
        \end{tikzcd}
        \caption{``The Arrow of Latent Behaviours.'' This commutative diagram summarises the effect of spatial and behavioural transformations over the $F$-coalgebra $(X,c)$, respectively modelled by $m$ and $b$: the behaviour map changes from $!_c$ to $!_{b\circ c\circ m}$. Latent behaviour analysis assumes $b=\id$.}
        \label{fig:TheArrow} 
    \end{figure}

\section{Motivation: Fault Injection via Carrier Transformations}
\label{sec:Latent:Motivation}
\todo[inline]{Small intro to faulty systems. You should have mentioned already somewhere in the intro that there are two ways to mutate the behaviour of a system in the coalgebra world: by transforming the carrier or by transforming the co-carrier. We only study transformations of the carrier.}
\todo[inline]{I feel like we are missing some stuff? How are we going to structure the introduction?}

Consider the automaton shown in Figure~\ref{fig:ExampleLatent}, which recognises the language of sequences of zeroes and ones that end in two consecutive ones; i.e., the language $(0+1)^*11$. 
This automaton is defined by the tuple $(\vec{X},\vec{x}_0,\delta,F)$, where the carrier is $\vec{X}=2\times2$, the initial state is $\vec{x}_0\colon1\rightarrow \vec{X}$ with $\vec{x}_0(\star)=(0,0)$, the transition function $\delta\colon \vec{X}\rightarrow 2\rightarrow\vec{X}$ is defined for $\vec{x}\in \vec{X}$ and $i \in 2$ by $\delta(\vec{x})(i)=(i,\vec{x}[0]),$ and the characteristic predicate of the set of accepting states is $F\colon\vec{X}\rightarrow 2$, where $F(1,1)=1$ and $F(x,y)=0$ otherwise; i.e. $(1,1)$ is the only accepting state. This automaton is not minimal, since the states $(0,0)$ and $(0,1)$ are bisimilar.

\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        \node[state,initial] (00) {$(0,0)$};
        \node[state, below right of=00] (01) {$(0,1)$};
        \node[state, above right  of=00] (10) {$(1,0)$};
        \node[state, accepting, below right of=10] (11) {$(1,1)$};
        \draw (00) edge[bend left, above] node{1} (10)
        (00) edge[loop above] node{0} (00)
        (01) edge[bend left, left] node{1} (10)
        (01) edge[bend left, above] node{0} (00)
        (10) edge[bend left, above] node{1} (11)
        (10) edge[bend left, right] node{0} (01)
        (11) edge[loop above] node{1} (11)
        (11) edge[bend left, above] node{0} (01)
        ;\end{tikzpicture}
    \caption{An automaton which recognises the language $(0+1)^*11$.}
    \label{fig:ExampleLatent}
\end{figure}

Now, %assume that the programmer is malicious, and they purposely 
consider a symmetry in the state space which maps $(a,b)$ to $(\lnot a, \lnot b)$. This transformation models some fault which could be introduced by a malicious programmer. Formally, %the programmer applies a 
we define the transformation $m\colon \vec{X}\rightarrow\vec{X}$ for $\vec{x}\in \vec{X}$ by $m(\vec{x})=(\lnot \vec{x}[0],\lnot \vec{x}[1])$. 
State transformations are applied before behaviour is computed; thus, if the current state is $\vec{x}=(a,b)$, when we intend to check whether $\vec{x}$ is accepting, we instead check whether $(\lnot a, \lnot b)$ is accepting, and when we intend to compute $\delta(i)(\vec{x})$, we instead compute $\delta(i)(\lnot a, \lnot b)$. 

\begin{figure}[t]
    \centering
\begin{tikzpicture}
    \node[state, initial, accepting] (00) {$(0,0)$};
    \node[state, below right of=00] (01) {$(0,1)$};
    \node[state, above right  of=00] (10) {$(1,0)$};
    \node[state, below right of=10] (11) {$(1,1)$};
    \draw (00) edge[bend right, above] node{1} (11)
    (00) edge[bend right, above] node{0} (01)
    (01) edge[bend right, above] node{1} (11)
    (01) edge[loop below] node{0} (01)
    (10) edge[loop above] node{1} (10)
    (10) edge[bend right, above] node{0} (00)
    (11) edge[bend right, above] node{1} (10)
    (11) edge[bend right, above] node{0} (00)
    ;\end{tikzpicture}
\caption{Automaton that models the faulty implementation, which now recognises $\varepsilon+(0+1)^*10$.}
\label{fig:Transformed}
\end{figure}
Figure~\ref{fig:Transformed} shows a model of the faulty system. This automaton recognises the language of sequences of zeroes and ones that are either empty or end in 10; i.e., $\varepsilon+(0+1)^*10$. 
Before we explain why the automaton in Figure~\ref{fig:Transformed} models the faulty system, we can test if this system recognises sequences $\varepsilon+(0+1)^*10$. %$(0+1)(0+1)^*$. 
To do so, let us consider pairs of states $[\vec{x},\vec{y}]$ where $\vec{x}=(x_1,x_2)$ and $\vec{y}=(y_1,y_2)$ such that the pair $\vec{x}$ follows the original behaviour, i.e., without faults, while $\vec{y}$ follows the faulty behaviour. 
The initial state is $[(0,0),(0,0)]$. %, since $(1,1)$ replaces $(0,0)$ due to the fault. 
The trace of the sequence $00$ is 
\begin{align*}
   [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(0)\times\delta(0)}[(0,0),(0,1)]\\
   &\xrightarrow{\id\times m}[(0,0),(1,0)]\xrightarrow{\delta(0)\times\delta(0)}[(0,0),(0,1)]\\
   &\xrightarrow{\id\times m}[(0,0),(1,0)]\xrightarrow{F\times F}[0,0],
\end{align*}
so $00$ is rejected by both automata. %Note that $\delta(0)(1,1)=(0,1)$, but since $(1,0)$ replaces all read uses of $(0,1)$, we apply the fault directly. 
Now, if we receive the sequence $10$, the resulting state trace is 
\begin{align*}
    [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(1)\times\delta(1)}[(1,0),(1,1)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,0)]\xrightarrow{\delta(0)\times\delta(0)}[(0,1),(0,0)]\\
   &\xrightarrow{\id\times m}[(1,0),(1,1)]\xrightarrow{F\times F}[0,1];
\end{align*}
the faulty automaton accepts $10$, but the original automaton does not. 
The trace of the sequence $11$ is 
\begin{align*}
    [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(1)\times\delta(1)}[(1,0),(1,1)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,0)]\xrightarrow{\delta(1)\times\delta(1)}[(1,1),(1,0)]\\
   &\xrightarrow{\id\times m}[(1,1),(0,1)]\xrightarrow{F\times F}[1,0],
\end{align*}
so $11$ is accepted by the original automaton, but rejected by the faulty automaton. 
For the sequence $110$, the resulting state trace is 
\begin{align*}
    [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(1)\times\delta(1)}[(1,0),(1,1)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,0)]\xrightarrow{\delta(1)\times\delta(1)}[(1,1),(1,0)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,1)]\xrightarrow{\delta(0)\times\delta(0)}[(0,1),(0,0)]\\
   &\xrightarrow{\id\times m}[(0,1),(1,1)]\xrightarrow{F\times F}[0,1];
\end{align*}
the faulty automaton accepts $110$, but the original automaton does not. Finally, the original automaton rejects the empty sequence $\varepsilon$, but the faulty automaton accepts it, since 
\begin{align*}
    [(0,0),(0,0)]\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{F\times F}[0,1].
\end{align*} 

% The map $m$ pairs each state with its corresponding faulty representation. %If there were no faults, the map $m$ would be the identity map. 
% The fault forces the state $(0,0)$ to behave like its image under $m$, i.e., the behaviour of $(0,0)$ in the faulty system should behave like $(1,1)$. Similarly, the state $(1,1)$ should behave $(0,0)$. 
%(We can alternatively see the function $m$ as a bad abstraction from the implementation.)

%There are now two final states: $(1,1)$ and $(0,1)$ since both states are preimages of $(1,1)$ under $m$.
We obtain the automaton shown in Figure~\ref{fig:Transformed} by ``copying'' the original behaviour from images of $m$ to their preimages. Figure~\ref{fig:ExampleWithFaults} shows this procedure for $(0,0)$ and $(1,1)$. This includes copying the behaviour under $\delta$ and under $F$. 

We preserve the initial state because $\vec{x}_0$ is a selection/construction/algebraic operation, not a behavioural/semantic/coalgebraic operation. We do not apply transformations to the results of algebraic operations to avoid aggregating the transformation erroneously due to composition of algebraic and coalgebraic operations. Consider the followign: the initial state $\vec{x}_0$ is of type $1\rightarrow\vec{X}$ which is algebraic, so the only way to apply $m$ to $\vec{x}_0$ is by composing it on the left, i.e., $m\circ \vec{x}_0(\star)$. Checking if the initial state is accepting in the original automaton corresponds to the expression $(F\circ\vec{x}_0)(*)$; however, the expression
\begin{align*}
    (F\circ m)\circ (m\circ\vec{x}_0)(\star)= (F\circ m)(1,1)=F(0,0)=0,
\end{align*}
applies $m$ twice, and it fails to properly check if the initial state of the faulty automaton is final. Instead, the correct expression is 
\begin{align*}
    (F\circ m)(\vec{x}_0)= (F\circ m)(0,0)=F(1,1)=1.
\end{align*}
% In other words, since $m(0,0)=(1,1)$, we copy the original behaviour of $(1,1)$ and we give it to $(0,0)$, including that $(1,1)$ is an accepting state; similarly, since $m(1,1)=(0,0)$ we copy the original behaviour of $(0,0)$ to $(1,1)$. 
% We do not change the initial state because 

\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        \node[state] (00) {$(0,0)$};
        \node[state, below right of=00] (01) {$(0,1)$};
        \node[state, above right  of=00] (10) {$(1,0)$};
        \node[state, below right of=10] (11) {$(1,1)$};
        \draw 
        (00) edge[above, bend left, dashed,color=gray] node[color=lightgray]{1} (10)
        (00) edge[loop above, dashed,color=gray] node[color=lightgray]{0} (00)
        % (01) edge[bend left, dashed,color=gray] (10)
        % (01) edge[bend left, below, dotted, color=gray](00)
        % (10) edge[bend left, dashed, color=gray] (11)
        % (10) edge[bend left, right, dotted, color=gray] (01)
        (11) edge[loop above, dashed, color=gray] node[color=lightgray]{1} (11)
        (11) edge[bend left, below, dashed, color=gray]node[color=lightgray]{0} (01)
        %Mutation Arrows
        (00) edge[color=gray, dotted] (11) 
        % (01) edge[color=red,dotted]  (10)
        % (10) edge[color=red, dotted]  (01)
        (11) edge[color=gray, dotted] (00)
        %New arrows
        (00) edge[bend right, below,color=red] node{0} (01)
        (00) edge[bend right, below,color=red] node{1} (11)
        (11) edge[bend right, above,color=red] node{0} (00)
        (11) edge[bend right, above,color=red] node{1} (10)
        % (11) edge[above] node{1} (1,0)
        % (11) edge[bend right, above] node[near start]{0} (00)
        ;\end{tikzpicture}
    \caption{Composition of the fault $m$ and the original behaviour for the states $(0,0)$ and $(1,1)$. The dotted, gray, bidirectional arrow in the centre models the effect of the fault $m$. The original behaviours appear as dashed, grey lines. The behaviour which results from the composition appears as solid, red lines.}
    \label{fig:ExampleWithFaults}
\end{figure}
We say that the faulty system is \emph{latent} with respect to the original system, since the application of the transformation $m$ reveals it, and $m$ is not the identity function. 
We cannot model every fault using transformations of the state space. The set of behaviours that we can obtain is limited; e.g., the behaviour of an automaton that accepts every sequence cannot be transformed by just transforming the state space. 
To transform an automaton which accepts all sequences into one that can reject some or all, we need a transformation of the \emph{behaviour}. 
Those transformations correspond to the arrow $F(X)\xrightarrow{b}F(X)$ in Figure~\ref{fig:TheArrow}. 
\todo[inline]{the final coalgebra is the place where spatial, behavioural, and coalgebras meet. Spatial transformations abstract a behaviour acting concurrently with the one we are currently studying, and that's why they are interesting to study.}
%However, systems revealed by transformations of type $F(X)\xrightarrow{b}F(X)$ are not latent by definition. %In this thesis, we are interested in seeing how far we can go with just carrier transformations; i.e., with latent behaviours.

We now present a general treatment for carrier transformations and latent behaviours in the context of $F$-coalgebras. 

\todo[inline]{Remark eventually that we cannot model every malicious behaviour of the programmer, only those that affect state, not functionality.}
\section{Latent $F$-coalgebras}
\todo[inline]{First write about the coalgebras and how they connect behaviours... then come back to this section.}
Coalgebras offer an interesting perspective for the study of systems. Given an $F$-coalgebra $(X,c\colon X\rightarrow F(X))$, each state $x\in X$ has an associated behaviour $c(x)\in F(X)$. In this section, we study the effect of a state transformation $m\colon X\rightarrow X$ over the $F$-coalgebra $(X,c)$. 

In terms of types, we can always compose the function $c$ with any carrier transformation $m$; the composition $c \circ m\colon X\rightarrow F(X)$ exists and is well defined. However, the behaviour of elements might be greatly affected. In particular, states which are bisimilar under $c$ might no longer be bisimilar under $c \circ m$. If $m$ preserves bisimilarity, then we say that $m$ is \emph{(behaviourally) consistent}.

\begin{definition}[Consistent Spatial Transformations]
Given an $F$-coalgebra $(X,c)$, any function of type $m\colon X\rightarrow X$ is a \emph{spatial transformation}. %A transformation $m\colon X \rightarrow X$ has \emph{finite support} iff $m(x)\neq x$ only for a finite number of $x\in X$. We denote the set of finitely supported transformations by $X^X_\omega$. 
A spatial transformation $m$ is \emph{(behaviourally) consistent} if and only if, whenever $x\sim_c y$, then $m(x)\sim_{c} m(y)$, for all $x,y \in X$. %We denote the set of consistent transformations by $X^X|_\sim$. %
\end{definition}
Henceforth, we consider only minimal systems, unless explicitly mentioned otherwise. 
\begin{corollary}
    If $(X,c)$ is a minimal $F$-coalgebra, then every spatial transformation %$m\colon X\rightarrow X$ 
    is consistent. 
\end{corollary}
A transformation function $m\colon X\rightarrow X$ changes the normal behaviour of $\mathbb{X}$, and it reveals the \emph{latent coalgebra of $\mathbb{X}$ under $m$}. 
\begin{definition}[Latent Coalgebra]
Given an $F$-coalgebra $\TheCoalgebra=(X,c)$ and a transformation $m$, the \emph{latent coalgebra of $\mathbb{X}$ under $m$} is $(X,c\circ m)$. 
\end{definition}
% \begin{align}
%     \mathbb{X}\circ m\triangleq(X,{(o\circ m, \delta\circ m })).
% \end{align}
The function $\TheLatentBehaviourOfIn{\cdot}{m}{c}\colon X\rightarrow \sigma F$ defines the \emph{latent behaviour} under $m$. The homomorphism $\TheLatentBehaviourOfIn{\cdot}{m}{\mathbb{X}}$ corresponds to the semantic mapping of the $F$-coalgebra $(X,c\circ m)$; that is, for $x\in X$, 
\begin{align}
\TheLatentBehaviourOfIn{x}{c}{m}\triangleq\TheBehaviourOfIn{x}{{c\circ m}}
\end{align} 

\begin{example}
\label{ex:Latent:TheExample}
Consider the automaton from Section~\ref{sec:Latent:Motivation} which recognises the language $(0+1)^*11$. Let $F$ be the functor $F(X)=2\times X^2$; we model this system with the $F$-coalgebra $(X,(F,\delta))$, where $X=2\times2$ and $(F,\delta)\colon X\rightarrow 2\times X^2$, defined for $(x,y\in X$ by
\begin{align}
    F(x,y)&\triangleq x \land y\\
    \delta(x,y)(i)&\triangleq (i,x).
\end{align}
Just like its automaton counterpart, this $F$-coalgebra is not minimal, since $(0,0)$ and $(0,1)$ are bisimilar
There are $|X|^{|X|}=256$ different spatial transformations, but that does not imply the existence of 256 different latent coalgebras; e.g., the transformations $\Delta_{(0,0)}$ and $\Delta_{(0,1)}$ yield isomorphic latent coalgebras. 
The transformation $m(x,y)=(\lnot x,\lnot y)$ reveals the latent coalgebra where 
\begin{align}
    (F\circ m)(x,y)&= \lnot x \land lnot y\\
    (\delta\circ m)(x,y)(i)&= (i,\lnot x).
\end{align}
The behaviour of states change when $m$ acts on $X$. In particular, the image of state $(0,0)$ under the semantic mapping is no longer the language $(0+1)^*11$ but $\varepsilon +(0+1)^*10$.
\end{example}
% \todo[inline]{There is no notion of distance or how different behaviours are in this setting. Things either are equal/isomorphic or they are not.}

LBA of an $F$-coalgebra $(X,X\xrightarrow{c} F(X))$ is the study of the effect that a spatial transformation $m\colon X\rightarrow X$ has over the behaviour of states in $X$, i.e., the shift in semantics from $c$ to $c\circ m$. It is also possible to change behaviour by composing $c$ with a \emph{behaviour transformation} $b\colon F(X)\rightarrow F(X)$ on the left. Both $(X,b\circ c\colon X\rightarrow F(X))$ and $(X,b\circ c\circ m\colon X\rightarrow F(X))$ are $F$-coalgebras, since the type requirement is satisfied. The effect of behaviour transformations in arbitrary systems are beyond the scope of this work. Nevertheless, there are systems where behaviour transformations and spatial transformations coincide: final $F$-coalgebras.

%\subsection{Latent Coalgebras of Final $F$-coalgebras}
A final $F$-coalgebra $(\sigma F, 1)$ has a behaviour function $1\colon \sigma F \rightarrow \sigma F$ that is an isomorphism. Since $\sigma F \simeq F(\sigma F)$, it naturally follows that 
\begin{align}
    \sigma F\rightarrow \sigma F \simeq \sigma F\rightarrow F(\sigma F) \simeq F(\sigma F)\rightarrow F(\sigma F).    
\end{align}
In other words, in the carrier of the final $F$-coalgebra, spatial transformations ($\sigma F\rightarrow \sigma F$), behavioural transformations ($F(\sigma F)\rightarrow F(\sigma F)$) and $F$-coalgebras ($\sigma F\rightarrow F(\sigma F)$) are in a one-to-one correspondence. 

Intuition tells us that $1\colon \sigma F \rightarrow F(\sigma F)$ should correspond to $\id_{\sigma F}\colon \sigma F\rightarrow \sigma F$ and should correspond to $\id_{F(\sigma F)}\colon F(\sigma F)\rightarrow F(\sigma F)$. The general form is given by the following proposition.
\begin{proposition}
    For every $F$-coalgebra $(\sigma F, c)$, there are transformations $m\colon \sigma F\rightarrow \sigma F$ and $b\colon F(\sigma F)\rightarrow F(\sigma F)$ such that the diagram in Figure~\ref{fig:FinalEquivalence} commutes.
\end{proposition}
\begin{proof}
    Since $1\colon \sigma F\rightarrow F(\sigma F)$ is an isomorphism, by taking $m=1^{-1}\circ c$ and $b=c\circ 1^{-1}$, the diagram in Figure~\ref{fig:FinalEquivalence} commutes.
\end{proof}
\begin{corollary}
    Every $F$-coalgebra $(\sigma F, c)$ is a latent coalgebra of $(\sigma F, 1)$ under some spatial transformation $m\colon \sigma F\rightarrow \sigma F$.
\end{corollary}

\begin{figure}[t] 
    \centering
    \begin{tikzcd}[column sep=1.5cm, row sep=1.5cm]
         \sigma F
            \arrow[r,"m"]
            \arrow[dr,"c"]
            \arrow[d,"1"']
        &\sigma F
            \arrow[d,"1"]
        \\
         F(\sigma F)
            \arrow[r,"b"']
        &F(\sigma F)
            %\arrow[u,"1^{-1}"']
    \end{tikzcd}
    \caption{Every $F$-coalgebra $(\sigma F, c)$ can be revealed from the final coalgebra $(\sigma F,1)$ by means of a transformation $m$ or a transformation $b$. In other words, it suffices to use spatial transformations $m$ and the final $F$-coalgebra to reveal all $F$-coalgebras of $\sigma F$, so behavioural transformations $b$ are unnecessary.}
    \label{fig:FinalEquivalence} 
\end{figure}
This property is exclusive to the carrier of the final coalgebra, because of the reversibility of the final map $1$, which formalises a correspondence between state and behaviour. For an arbitrary $F$-coalgebra $(X,c)$, only some latent $F$-coalgebras can be revealed by spatial transformations $m\colon X\rightarrow X$.
\todo[inline]{A few words about completeness would be good here: you need not work directly on final coalgebras, that is what specification languages are for! }

%\subsection{$F$-Coalgebras as Endofunctions}
Given a final $F$-coalgebra $(\sigma F, 1)$ and an arbitrary coalgebra $(\sigma F, c)$, the spatial transformation $\omega\colon \sigma F\rightarrow \sigma F$ defined by $\omega\triangleq 1^{-1}\circ c$ implements $c$. The identity spatial transformation implements $1$. This duality between $F$-coalgebras and spatial transformations in $\sigma F$ enables the composition of $F$-coalgebras in $\sigma F$.
%This treatment simplifies the composition of $F$-coalgebras in $\sigma F$. 

%When we compose $F$-coalgebras we are applying their behaviour functions sequentially. 
Given two $F$-coalgebras $(\sigma F, c_1)$ and $(\sigma F, c_2)$ whose respective spatial transformation implementations are $\omega_1$ and $\omega_2$, the composition $\omega_2\circ \omega_1$ gives rise to the following equivalent concepts:
\begin{itemize}
    \item the $F$-coalgebra $(\sigma F, c_2\circ 1^{-1}\circ\omega_1)$,
    \item the latent coalgebra of $(\sigma F, c_2)$ under $\omega_1$,
    \item the latent coalgebra of $(\sigma F, 1)$ under $\omega_2\circ \omega_1$.
\end{itemize}
In summary, we can represent $F$-coalgebras whose carrier is $\sigma F$ by endofunctions in $\sigma F$, and we can reason about their composition as we would with functions in the monoid of endofunctions $(\sigma F\rightarrow \sigma F, \circ, \id)$.

\todo[inline]{Explain that this corresponds to the point of The Arrow: $!c$ takes you from $X$ to $\sigma F$, and you can use $\omega$ to reveal a latent coalgebra of $(\sigma F, 1)$. This arrow $\omega$ models the behavioural change from $!c$ to $!_{b\circ c\circ m}$.}
In the following, we return to arbitrary $F$-coalgebras $(X,c)$, but we keep in mind the following: when we reveal a latent coalgebra of $(X,c)$ under a spatial transformation $m$, we are implicitly sequentially composing the behaviour function $c$ with the behaviour function of the $F$-coalgebra implemented by $m$; first we apply $m$ and then we apply $c$.

\section{Latent-Behaviour Analysis}
\todo[inline]{Describe in terms of coalgebras an introduction for the three application topics we have: attacker classification, CPS redesign and Side-channel repair.}
LBA is the study of the effects that spatial transformations have on the behaviour of the system. Just like in geometry, some spatial transformations may preserve some properties, while others may completely destroy the functionality of the system. In this section, we present three ideas for LBA to study three aspects of systems: \emph{attacks and counter-attacks}, \emph{attacker classification}, and \emph{side-channel repair}.

Consider the system from Section~\ref{sec:Latent:Motivation} and it coalgebraic equivalent presented in Example~\ref{ex:Latent:TheExample}. This example has 256 different spatial transformations, which we can use to model attacks on the system. 
\todo[inline]{I dunno where I was going with this}

% {\color{blue} Working with endofunctions is nice because you can study e.g. those with finite support. Endofunctions with finite support finitely compose nicely, and you can use them to model incremental changes to behaviour.

% What I need to do though is to hint towards potential applications. This section describes that in final coalgebras it suffices to compose endofunctions to model behaviours. In arbitrary coalgebras however, we can 
% }
% Composition of $F$-coalgebras is non-commutative. 
% \begin{theorem}[Fundamental Theorem of Latent-Behaviour Analysis]
%     \label{theo:Fundamental}
%     The semantic map-ping of the $F$-coalgebra $(X,c\circ m\colon X\rightarrow F(X))$ factors through the semantic mapping of the $F$-coalgebra $(m(X),c\colon m(X)\rightarrow F(m(X)))$
%     \todo[inline]{This probably needs to use bounded functors.}
% \end{theorem}
%This composition is in general not commutative.

% Consider an example in automata: we define $m\colon \sigma F\rightarrow \sigma F$ such that 
% \begin{align*}
%     m(\phi)(w)=
% \begin{cases}
%     \phi(w), \quad \text{if $w$ ends in 1},\\
%     0,\quad \text{otherwise}.
%     % \lnot \phi(w), \quad \text{if $w\varepsilon$}\\
%     % \phi(w), \quad \text{otherwise}.
% \end{cases}
% \end{align*}
% In other words, $m$ removes all sequences that do not end in $1$ from the language characterised by $\phi$. We obtain $c=1\circ m$

% In the case of automata, what does it mean for $c(L)=L'$ Normally what we have is $L\mapsto (0|1, 0\mapsto L_0, 1\mapsto L_1)$. 

% \todo[inline]{Something is not right: In the case of automata, }


% , and such a set of revealed behaviours is determined by the available \emph{gadgets}.

% \section{Gadgets}
% In the context of return-oriented programming~(\cite{ROP}), a \emph{gadget} is a code snipped that is part of the original program, and it is exploited by attackers to hijack the control flow once they affect the return addresses of functions. In the context of LBA, given an $F$-coalgebra $(X,c)$, if $c$ defines the program, then the components of $c$ define the set of \emph{gadgets} we can use to change the behaviour of the system.
% \begin{definition}[Gadgets]
%     Let $\mathbb{X}=(X,c)$ be an $F$-coalgebra. 
%     A \emph{gadget of $\mathbb{X}$} is a pair $(x,c)$ where $x\in X$. %The set of \emph{gadgets of $\mathbb{X}$} by the graph of $c$. 
% \end{definition}

% A gadget $(x,c)$ is a behavioural building block. We can interpret the gadget $(x,c)$ as the action of applying $c$ at $x$, so $(m(x),c)$ models the action of applying $c$ to $m(x)$. 

% In the example presented in Section~\ref{sec:Latent:Motivation}, there are four gadgets. Each gadget gives each spatial transformation $m$ a chance to further alter the behaviour of the system. 
% \todo[inline]{Where do you want to go with this? It looks interesting, but not useful. }

% In the following, we work on arbitrary $F$-coalgebras $(X,c)$ and only consider spatial transformations to

% \todo[inline]{If we want $a$ to change with time there is no need to do anything fancy! We can enhance the carrier by doing $X'=X\times \mathbb{N}$ or $X'=X\times [X\rightarrow 2]$; with this, $X$ is enhanced by a natural number counter or a set of conditions to make the dynamics of the transformation coalgebra more interesting. Maybe there is even no need to do changes, it all depends on how informative $X$ is. let's see}

% \todo[inline]{This means that the problem becomes a "searching for the next candidate at every step" problem. Alternatively, you could learn to compose solutions too. }
% \todo[inline]{Maybe we can also do something exciting: eventuality -> at some point in time, the behaviour you want becomes apparent, i.e. $\TheBehaviourOf{x_0}^w=\rho$ for some $w$}

\subsection{Quantifying and Improving Robustness}
\todo[inline]{The idea is that if we can design attacks, that yield new systems, we can design counter attacks that perhaps return the original system back. This is an introduction to the TOPS papers and the one we worked with Martin before}
\begin{definition}[Behavioural Property]
    \label{def:Latent:BehaviouralProperty}
    Let $F$ be a functor for which a final $F$-coalgebra $(\sigma F, 1)$ exists. A \emph{behavioural property} $P$ is a function $P\colon \sigma F\rightarrow 2$. Given an arbitrary $F$-coalgebra $(X,c)$, we say that $x\in X$ satisfies the behavioural property $P$ if and only if $(P\circ !_c)(x)=1$.
\end{definition}
Behavioural properties come in all shapes and forms, and are often described using logics like LTL~\cite{LTL}. CTL~\cite{CTL}, and $\mu$ calculus~\cite{MuCalculus}. Let us for now assume that we have a set of behavioural properties $\mathcal{R}=\set{R_1, \ldots, R_n}$ which model both functional and security requirements of the system. We discuss concrete ways to define these behavioural properties in Chapters~\ref{ch:Classification} and \ref{ch:CPSRobustness}.

Consider the following problem: we are given an arbitrary $F$-coalgebra $(X,c)$, an initial state $x_0\in X$, and a set of behavioural properties $\mathcal{R}=\set{R_1, \ldots, R_n}$. Normally, we would check if $x_0$ satisfies all behavioural properties in $\mathcal{R}$, but now we consider a spatial transformation $m\colon X\rightarrow X$, and we want to check if $x_0$ still satisfies all the given behavioural properties in the resulting latent coalgebra revealed by $m$.

We might think that it suffices to check $(R_i\circ !_c)(m(x_0))=1$ for each requirement $R_i$, but that would be incorrect as illustrated by the following example.
\begin{example}[Wrong Verification]
    In the context of Example~\ref{ex:Latent:TheExample}, the functor is $F(X)=2\times X^2$ has a final $F$-coalgebra $(2^{2^*},(\varepsilon?,(\cdot)'))$ where $\varepsilon? \colon 2^{2^*}\rightarrow 2$ checks whether the empty sequence $\varepsilon$ belongs to the language and $(\cdot)'\colon 2^{2^*}\rightarrow (2\rightarrow {2^{2^*}})$ computes the Brzozowski derivative~\cite{BrzozowskiDerivative} of the language.  
    \todo[inline]{Maybe move to preliminaries?}
    Let $R\colon 2^{2^*}\rightarrow 2$ be the behavioural property defined by $R(\phi)\triangleq \phi \sim \varepsilon+(0+1)^*10$, for $\phi \in 2^{2^*}$. The property $R$ is not satisfied by any state of the original $F$-coalgebra, so $(R\circ !_c)(m(x_0))$ would be 0 for all spatial transformations $m$; nevertheless, $R$ is satisfied by $x_0$ in the latent coalgebra revealed by the spatial transformation $m(x,y)=(\lnot x, \lnot y)$ used in Example~\ref{ex:Latent:TheExample}, since it is the language the state $(0,0)$ recognises in the latent coalgebra. 
\end{example}
Part of the novelty of LBA is that we can study a latent coalgebra $(X, c\circ m)$ just as we would study the original coalgebra $(X, c)$. By this, we mean that we can apply testing and verification techniques without complication. In the following, we illustrate how we can use spatial transformations to model attacks which target the state of systems rather than the program, and we study the details of this approach in Chapter~\ref{ch:CPSRobustness} when we apply it to cyber-physical systems.
\begin{definition}[State/Behaviour-based Attacks]
    \label{def:Latent:StateAttacks}
    Given an $F$-coalgebra $(X,c)$, we define the set of its \emph{state-based attacks} corresponds to be the set of its spatial transformations, i.e., $X^X$. 
    We also define the set of its \emph{behaviour-based attacks} by $F(X)^{F(X)}$. 
    \end{definition}
Under this definition, LBA studies the effect of state-based attacks. Henceforth, when we refer to an attack, we implicitly mean a state-based attack (unless stated otherwise). In the particular case of final $F$-coalgebras, their state-based attacks coincide with their behaviour-based attacks. 

We know that an attack $m$ reveals a latent coalgebra $(X, c\circ m)$ which may or may not satisfy the same behavioural properties that $(X, c)$ satisfies. We could check whether $(X,c\circ m)$ satisfies all requirements in $\mathcal{R}$, but this is not very informative if we arbitrarily choose $m$. We propose to systematically generate a set of spatial transformations $\mathcal{M}=\set{m_1,\ldots, m_p}$ based on some attacker model, and test whether each revealed latent coalgebra $(X, c\circ m_i)$ satisfies each requirement $R_j$ for $m_i\in \mathcal{M}$ and $R_j\in \mathcal{R}$. If a requirement $R$ is not satisfied in some latent coalgebra $(X, c\circ m)$, then the attacker can use $m$ to break $R$ in the original system $(X,c)$; in this case, we say that \emph{the attack $m$ breaks the requirement $R$}. If no attack in $\mathcal{M}$ breaks any requirement in $\mathcal{R}$, then we say that the system is \emph{robust} against the attacker model that generated $\mathcal{M}$. This approach gives us a qualitative notion of robustness.

We can extend qualitative robustness into quantitative robustness by discounting broken requirements. More precisely, given $(X,c)$, $\mathcal{M}$, and $\mathcal{R}$ such that $|\mathcal{R}|=n$, we can define the set $\mathcal{M}[\mathcal{R}]$ of requirements in $\mathcal{R}$ that are broken by one or more attacks in $\mathcal{M}$; similarly $m[\mathcal{R}]$ is the set of requirements that $m$ breaks. We estimate the robustness of the system by the formula 
\begin{align*}
    \sum_{i=i}^n{w_i(1-(R_i\in \mathcal{M}[\mathcal{R}]))},
\end{align*}
where $w_i\in \mathbb{R}^+$ is a weight which models the importance of requirement $R_i$.

Let us consider the case where $(X,c)$ fails a non-empty set of requirements; this set, given the definitions, is equal to $\id[\mathcal{R}]$. Now, let $\mathcal{K}=\set{k_1, \ldots, k_q}$ be an arbitrary set of spatial transformations independent of $\mathcal{M}$; we say that a spatial transformation $k\in \mathcal{K}$ \emph{repairs $(X,c)$} if $k[\mathcal{R}]\subset \id[\mathcal{R}]$; we say that $k$ \emph{fully repairs $(X,c)$} if $k[\mathcal{R}]$ is empty. The set spatial transformations $\mathcal{K}$ corresponds to a repair toolkit, which we generate systematically just like we did with the set of attacks $\mathcal{M}$. We study the process of system repair in more detail in Chapter~\ref{ch:SideChannelRepair}.

We now consider an analysis that combines both $\mathcal{M}$ and $\mathcal{K}$ as follows. If an attack $m\in \mathcal{M}$ breaks some requirements, is there a \emph{counter attack} $k$ that fully repairs $(X,c\circ m)$? If so, we can improve the robustness of the system $(X,c)$ by transforming it into $(X,c\circ m \circ k)$ whenever we detect that the attack $m$ is affecting $(X,c)$; we refer to this dependent notion of robustness as \emph{latent robustness}, and we explore this concept in cyber-physical systems during Chapter~\ref{ch:CPSRobustness}.

% Given an attacker model which generates the set of attacks $\mathcal{M}$, 

% Considering that latent coalgebras are coalgebras, we could apply LBA to latent coalgebras. 

% There are two dimensions we can explore: one, given $(X, c)$ and $m$, we can iterate over $\mathcal{R}$ and check whether $(X,c)$ and $(X,c\circ m)$ satisfy $R$ for $R\in \mathcal{R}$, or two, given $(X,c)$ and $\mathcal{R}$
% % Different $F$-coalgebras have different sets of attacks. In our framework, a minimal $F$-coalgebra $(X,c)$ has as many attacks as $|X|^{|X|}$.

\subsection{Classification of Attackers}
We have not discussed how we systematically generate attacks and counter attacks for an $F$-coalgebra $(X,c)$. Both attacks and counter attacks are spatial transformations, so they are elements of the set $X^X$. %Depending on the properties of $X$, we obtain different ways to generate attacks. For example, if $X$ is enumerable and finite, then their spatial transformations are also enumerable. 
Our goal is the following: given an \emph{attacker model} (whatever that is), we want to automatically obtain a set of attacks $\mathcal{M}$, which we can use to perform LBA on the $F$-coalgebra $(X,c)$. We can use the results of this analysis to quantify robustness as shown in Chapter~\ref{ch:CPSRobustness}. In this section, we are interested in also varying the attacker model, and in comparing them.

Consider an $F$-coalgebra $(\vec{X},c)$ such that $\vec{X}$ is a product type of finite types; e.g., $\vec{X}=2\times 2$. We use the coordinates of $\vec{X}$, e.g., $\fst$ and $\snd$ to define attacker models. 
\begin{definition}[Invariant Attacker Model]
\label{def:Latent:InvariantAttackerModel}
Let $(\vec{X},c)$ be an $F$-coalgebra such that $\vec{X}$ is a product type whose coordinates are $\Pi=\set{\pi_1, \ldots, \pi_n}$ where $\pi_i\colon \vec{X}\rightarrow A_i$; an \emph{invariant attacker model} $\alpha$ is a mapping which takes each coordinate $\pi_i\in\Pi$ to a set of transformations $\mathcal{T}_i\subseteq A_i^{A_i}$ such that the following conditions are satisfied:
\begin{itemize}
    \item the attacker can always do nothing, i.e., $\id_{A_i}\in \mathcal{T}_i$; 
    \item if the attacker can transform the coordinate $\pi_i$ using $f\in \mathcal{T}_i$, and they can transform $\pi_i$ using $g\in \mathcal{T}_i$, then they should be able to transform $\pi_i$ using $g\circ f$; i.e., if $f,g\in \mathcal{T}_i$, then $g\circ f\in \mathcal{T}_i$.
\end{itemize}
\end{definition}
For a coordinate $\pi\in \Pi$, a transformation $f\in\alpha(\pi)$ acts on a state $\vec{x}\in \vec{X}$ by substituting the value of coordinate $\pi_i$ at state $\vec{x}$ with $f(x[\pi_i])$; i.e., we can extend $f$ to a function of type $f^\flat\colon X\rightarrow X$ defined by 
\begin{align*}
    f^\flat(\vec{x})[\pi_j]\triangleq\begin{cases}
        f(\vec{x}[\pi_j]),&\quad\text{if $i=j$};\\
        \vec{x}[\pi_j],&\quad\text{otherwise.}
    \end{cases}
\end{align*}
The natural extensions from $f\in \alpha(\pi)$ to $f^\flat\in \vec{X}^{\vec{X}}$ lifts the attacker model $\alpha$ into a set of generator functions for the set $\AsSequence{\alpha}\subseteq \vec{X}^{\vec{X}}$, where $\AsSequence{\alpha}$ is smallest set satisfying the following conditions:
\begin{itemize}
    \item for all $\pi\in \Pi$ and $f\in \alpha(\pi)$, $f^\flat \in \AsSequence{\alpha}$;
    \item for all $f,g\in \AsSequence{\alpha}$, $g\circ f \in\AsSequence{\alpha}$.
\end{itemize}

\begin{example}[Some Invariant Attacker Models for Example~\ref{ex:Latent:TheExample}]
\label{ex:Latent:ExampleAttacker}
    Since $\vec{X}=2\times 2$, we have two coordinates: $\fst\colon \vec{X}\rightarrow 2$ and $\snd\colon \vec{X}\rightarrow 2$ mapping $(x,y)\xmapsto{\fst}x$ and $(x,y)\xmapsto{\snd}y$. The trivial attacker model is an attacker that does nothing, and it corresponds to the attacker model $\id$ which maps $\fst$ to $\set{\id_2}$ and $\snd$ to $\set{\id_2}$. The lifting of these functions yield the set $\AsSequence{\id}=\set{\id_{2}^\flat}$ with $\id_{2}^\flat=\id_X$.

    We consider three other attackers now: one which has full control over $\fst$ but no control over $\snd$, one which has full control over $\snd$ but not over $\fst$, and one attacker that has full control over both $\fst$ and $\snd$. The attacker with no control over $\fst$ or $\snd$ is the attacker which generates $\AsSequence{\id}$. 

    The attacker with full control over $\fst$, denoted $\alpha_1$, maps $\snd$ to $\set{\id_2}$ and $\fst$ to $2^2$. The set $\AsSequence{\alpha_1}$ is the set of functions in $\vec{X}^{\vec{X}}$ which only affect the $\fst$ coordinate. Similarly, the attacker with full control over $\snd$, denoted $\alpha_2$, maps $\fst$ to $\set{\id_2}$ and $\snd$ to $2^2$. Dually, the set $\AsSequence{\alpha_2}$ is the set of functions in $\vec{X}^{\vec{X}}$ which only affect the $\snd$ coordinate. We study these type of attackers which invariantly affect only one coordinate in Chapter~\ref{ch:Classification}. 

    There are attackers with partial control over $\fst$ and $\snd$; e.g., an attacker $\beta$ which maps $\fst$ to $\set{\Delta_1, \id}$ (i.e., $\Delta_1$ is the constant function that maps $b\in 2$ to 1), which generates $\AsSequence{\beta}=\set{\Delta^\flat_1, \id_2^\flat}$, where
    \begin{align*}
        \Delta^\flat_1(\vec{x})[\fst]=1,\quad\text{and}\quad \Delta^\flat_1(\vec{x})[\snd]=\vec{x}[\snd].
    \end{align*}
    Note that $\AsSequence{\beta}\subseteq\AsSequence{\alpha_1}$. Henceforth we only consider attackers which have full control over a particular set of coordinates since we did not find any practical scenarios where restricting the control of attackers over a particular coordinate offered a significant gain over the attacker with full control over such a coordinate.

    The attacker with full control over $\fst$ and $\snd$, denoted $\alpha^*$, can affect both $\fst$ and $\snd$ at the same time. However, this does not mean that $\AsSequence{\alpha^*}$ is equal to $\vec{X}^{\vec{X}}$, since there are still functions that cannot be generated by the combination of individual effects on independent coordinates. For example, consider the function $m\colon \vec{X}\rightarrow \vec{X}$ from Example~\ref{ex:Latent:TheExample} where $m(x,y)=(y,x)$; this function cannot be written in terms of a product function $f\times g\colon 2\times 2\rightarrow 2\times 2$, with $f\colon 2\rightarrow 2$ and $g\colon 2\rightarrow 2$.
    In Chapter~\ref{ch:CPSRobustness}, we add a more flexibility to attacker models so that they are no longer invariant, and we can generate arbitrary functions in $\vec{X}^{\vec{X}}$.
\end{example}
Given an $F$-coalgebra $(\vec{X},c)$ where $\vec{X}$ is a product type of finite types whose coordinates are $\Pi=\set{\pi_1,\ldots,\pi_p}$, and a list of requirements $\mathcal{R}=\set{R_1, \ldots, R_n}$, we can systematically generate invariant attacker models by choosing a subset of coordinates in $\Pi$. Under this formulation, the set of invariant attacker models is characterised by $\ThePowersetOf{\Pi}$. The attacker model corresponding to $\emptyset$ is the passive attacker, and the attacker 

Now that we have a systematic way to generate attacker models as well as attacks, we can combine the robustness LBA with the systematic generation of attacker models to classify attacker models. More precisely, 

\begin{definition}[Attack Ordering]
    Given two attacks $m_1, m_2$ and an $F$-coalgebra $\TheCoalgebra$, we say that $m_1\lesssim_\TheCoalgebra m_2$ if and only if $\supp(m_1) \subseteq \supp(m_2)$, and $m_1(x)\sim_\TheCoalgebra m_2(x)$ for all $x\in \supp(m_1)$. In other words, any $x$ that $m_1$ mutates can also be mutated by $m_2$ in the same way, in the context of the coalgebra $\TheCoalgebra$. We omit the subscript $\TheCoalgebra$ when it is clear from the context, or it is irrelevant.
    \end{definition}

{\color{red}
 \subsubsection{A Partial Order of Attackers}
 \todo[inline]{This should go on a different chapter}
\todo[inline]{We know how to quantify attackers in terms of exact latent behaviours, but latent behaviours themselves have an order (they are languages i.e. sets). What about the relationship among them? Do stronger attackers need to recognise more languages, what if a language implies another? how do attackers relate there then?}


This notion of attack ordering is a bit more general than one that uses equality (i.e., requiring $m_1(x)= m_2(x)$ instead of $m_1(x)\sim_\TheCoalgebra m_2(x)$), as it lets us focus directly on behaviour, and not on structure. If the coalgebra $\TheCoalgebra$ is minimal, then $m_1(x)= m_2(x)$ if and only if $m_1(x)\sim_\TheCoalgebra m_2(x)$, due to the coinduction proof principle.

\begin{definition}[Attack Execution]
Given an attacker $A$, an $F$-coalgebra $\TheCoalgebra=(X,c)$, and an arbitrary attack $m\in X_\omega^X$, we say that \emph{$A$ can execute the attack $m$} if and only if there exists an attack $m'\in \texttt{attacks}(A)$ such that $m\lesssim m'$.
%\begin{align}
%m' (x)\sim m (x), \quad \text{for all $x\in \supp(m)$}.
%\end{align}
%In such a case, we write $m'\lesssim m$.
\end{definition}
 
\begin{definition}[Attacker Ordering]
Let $\TheCoalgebra$ be an $F$-coalgebra whose components are $\Pi$. The partial order relation $\leq$ in the set of attackers $\TheFinitePowersetOf{\Pi}$ by its set inclusion, i.e. $A_1 \leq A_2$ if and only if $A_1 \subseteq A_2$. 
\end{definition}
This attacker ordering is \emph{monotonic} with respect to the \texttt{attacks} function: if $A_1 \leq A_2$, then any attack carried out by $A_1$ can be executed by $A_2$. %With it, we can define minimal attackers.

Monotonicity offers us mainly two advantages: 1) we can plan the order of attackers to be checked, and 2) we can propagate the results in case a solution fails.
\todo[inline]{Explain this better. You really need to have clear notions of solution and problems.}
% \begin{definition}[Minimal Attacker]
% \todo[inline]{Probably one of the most esoteric definitions here. It is wrt a particular problem? a particular attack, a property?}
% \end{definition}

%\todo[inline]{Should we just focus on DTS? NO!  The DTS I wanted to use does not have loops, so it is clear that we can keep doing this in the current modelling.}
}
% \begin{definition}[Emulation Problem]
% We say 
% \end{definition}
 
%  \section{Solving Latent Vulnerability Problems}
 
%  \subsection{Alternative formulations}
%  \begin{definition}[Target Value]
% Given an $F$-coalgebra $\TheCoalgebra=(X,c)$ with components in $\Pi$, a \emph{target value} is a proposition $x[\pi]==v$, modelled by the triple $(x,\pi,v)$ where $x\in X$, $\pi\in \Pi$ and $v$ is a value in the range of component $\pi$.
% \end{definition}
 
% \subsection{Exhaustive Search}
% Given an attacker $A$ of an $F$-coalgebra $\TheCoalgebra=(X,c)$ and a target behaviour $\sigma$, we could perform an exhaustive search over the domain of its attacks if the carrier $X$ is finite.  A naive, exhaustive search would choose an attack $m$, mutate $\TheCoalgebra$, then perform a bisimulation check to see if there exists a state $x$ such that its latent behaviour $\TheLatentBehaviourOfIn{x}{m}{\TheCoalgebra}$ is equal to $\sigma$.

% Since the search space is finite, if we cannot find an attack $m$ within the capabilities of $A$, then the system $\TheCoalgebra$ is safe with respect to $A$.

% \begin{example}
% \todo[inline]{For the example we can show that it can be solved}
% \end{example}


% \subsection{Using SMT Solvers}
% Due to our formulation, we have a perfect information deterministic game, like Chomp~\cite{Chomp}. Our idea is to leverage an SMT solver to give us a winning move for the attacker, or prove that such move does not exist. For the remainder of this section, we focus on $\DTS$-coalgebras.

% \todo[inline]{Rephrase this as a reachability problem. i.e. instead of a target value, use a set of goal states defined by the target values.}
% \todo[inline]{HERE I AM}
% \begin{definition}[Winning Latency Games]
% Let $A$ be an  attacker, $\TheCoalgebra=(X,\gamma,\delta,x_0)$ be a pointed $\DTS$-coalgebra, and consider a set of target values $(\pi_1,v_1),...,(\pi_n,v_n)$. We say that the attacker $A$ \emph{wins the latency game in zero steps} if and only if there exists an attack $m$ in $\texttt{attacks}(A)$ such that $m(x_0)[p_k]=v_k$, for $k=1..n$. If a solution is found in zero steps, then all target components $\pi_1$ to $\pi_n$ must be in control of $A$, i.e., $\set{\pi_1, \ldots, \pi_n}\subseteq A$.

% The attacker $A$ \emph{wins the latency game in $\tau$ steps given the inputs $(i_1, \ldots, i_\tau)$ with the attack $m$ at state $x_{\tau}$} if and only if there exists a sequence of states $(x_1, \ldots, x_\tau)$, where
% \begin{align}
% %m_{\tau+1}(x_{\tau +1})=x_\tau(
% x_{t+1}=\delta(m (x_{t}))(i_t), \quad \text{for $t=0..{\tau-1}$}
% \end{align}
% and
% \begin{align}
% m(x_\tau)[p_k]=v_k,\quad \text{ for $k=1..n$.}
% \end{align}
% \end{definition}


% \begin{proposition}[Composition through Emulation]
% \todo[inline]{There are several ways to compose attackers: through $\delta$ and through $m$. The message I want to carry across is the following: if you know that you can solve a latency game from a state $x$, then 
%  I already have a notion of winning over time, so I just need to emulate the attack of other attackers to reach my goal.}
% If an attacker $A$ can win a latency game in $\tau$ steps given the inputs $i_1, \ldots i_{\tau}$ in the pointed $\DTS$-coalgebra $(X,\gamma,\delta, x_{0})$ with an attack $m$, then an attacker $A'$ can win the same latency game in $\tau+t$ steps given the input $i_1, i_2, \ldots i_{\tau+1}$ in the pointed $\DTS$-coalgebra $(X,\gamma,\delta, x_{-t})$ if and only if 
% \begin{align}
% \delta
% \end{align}

% %Given a pointed $\DTS$-coalgebra $(X,\gamma,\delta, x_0)$, an attacker $A_0$ can win a given latency game in ${\tau+1}$ steps given the inputs $(i_1, \ldots, i_\tau, i_{\tau+1})$ with some attack $m$ at some state $x_{\tau+1}$ if and only if there exists an attacker $A_{\tau}$ that can win the given latency game in one step in the pointed $\DTS$-coalgebra $(X,m\gamma,\delta, x_{\tau})$.
% \end{proposition}
% \begin{proof}
% The main objective of $A_0$ is to reach state $x_{\tau}$ and from there 
% \end{proof}


%\begin{proposition}
%\label{sec:Incompleteness}
%Given an arbitrary $F$-coalgebra $\mathbb{X}=(X,c)$ and a behaviour $\rho\in \sigma F$, there may not exist a transformation $m\colon X\rightarrow X$ such that $\rho$ is a latent behaviour of $\mathbb{X}$ under $m$.
%\end{proposition}
%\begin{proof}
%We provide a counterexample for the opposite proposition, that is, there exists a transformation $m\colon X\rightarrow X$ such that $\rho$ is a latent behaviour of $\mathbb{X}$ under $m$, for all $F$-coalgebras and all behaviours in $\sigma F$. 
%Consider, for the functor $F=2\times \texttt{id}^2$, a single-state $F$-coalgebra that accepts all sequences; this $F$-coalgebra cannot display a latent behaviour different from its original behaviour.
%\end{proof}


\subsection{System Repair}
\todo[inline]{Enforcement is one of those problems where you have an original system and you want to still preserve the essence while changing the properties. What we do with side channels is this: we take a program, we slightly modify it, and we prove that we enforced something. I have to change things a bit here, because the program has to be the state, but that's ok, since I can model a coalgebra that counts the number of memory accesses and all that. }

\section{Future work}
\todo[inline]{This should go in the last chapter!}
We would like to consider two problems related to latent behaviours: 
\begin{itemize}
\item How can we use transformations ourselves to repurpose a system that is already been defined?
\item How can an attacker use transformations to force a behaviour they want?
\end{itemize}
\todo[inline]{Note that, ultimately, both questions need a method to solve an equation for a transformation. That is, given a target behaviour and an a source coalgebra, how do you solve the problem of finding a transformation that helps you display the behaviour you want? Is it even possible?}



