%!TEX root = ../main.tex
% Chapter Template


\chapter{Latent-Behaviour Analysis, Coalgebraically} % Main chapter title
\label{ch:LatentBehaviours} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\todo[inline]{Find a suitable quote?}
\begin{quote} 
%If you only do what you can do, you will never be more than what you are now.
"As you adequately put, the problem is choice. But we already know what you are going to do, don't we?" -- The Architect.
\end{quote} 

\section{Introduction}
\todo[inline]{Give an interesting motivational example: What is the notion of latent behaviour? Why do we care about them? How is it useful to study them?}
The objective of this section is to explain the commutative diagram presented in Figure~\ref{fig:TheArrow}. This diagram, which we refer to as ``The Arrow of Latent Behaviours,'' illustrates how spatial and behavioural transformations affect the behaviour of an $F$-coalgebra $(X,c)$ by changing the behaviour map from $!_c$ to $!_{b\circ c\circ m}$. 

\begin{figure}[h]
        \centering
        \begin{tikzcd}[column sep=1.75cm, row sep=1cm]
            &\sigma F
                \arrow[dr,swap,"\omega"']
            &
            \\ 
            X  
                \arrow[dd,"c"] 
            & X
                \arrow[l, swap, "m"]
                \arrow[u, "!_{c}"]
                \arrow[r,dotted, swap, "!_{b\circ c\circ m}"]
            &\sigma F 
                %\arrow[dd, "\simeq","\omega"']
                \arrow[dd, "1"]
                \arrow[dr, "\textbf{id}"]
            \\
            &&&\sigma(F)
            \\
            F(X)     
                \arrow[r, swap, "b"]
            &F(X)
                \arrow[d, swap, "F(!_{c})"]
                \arrow[r, dotted, "F(!_{b\circ c\circ m})"] 
            &
            F(\sigma F)
                %\arrow[ur, swap, "\omega^{-1}"]
                \arrow[ur, swap, "1^{-1}"]
            \\
            &F(\sigma F)
                \arrow[ru, swap, "F(\omega)"]
            &
        \end{tikzcd}
        \caption{``The Arrow of Latent Behaviours.'' This commutative diagram summarises the effect of spatial and behavioural transformations over the $F$-coalgebra $(X,c)$, respectively modelled by $m$ and $b$: the behaviour map changes from $!_c$ to $!_{b\circ c\circ m}$. Latent behaviour analysis assumes $b=\id$.}
        \label{fig:TheArrow} 
    \end{figure}

\section{Motivation: Fault Injection via Carrier Transformations}
\label{sec:Latent:Motivation}
\todo[inline]{Small intro to faulty systems. You should have mentioned already somewhere in the intro that there are two ways to mutate the behaviour of a system in the coalgebra world: by transforming the carrier or by transforming the co-carrier. We only study transformations of the carrier.}
\todo[inline]{I feel like we are missing some stuff? How are we going to structure the introduction?}

Consider the automaton shown in Figure~\ref{fig:ExampleLatent}, which recognises the language of sequences of zeroes and ones that end in two consecutive ones; i.e., the language $(0+1)^*11$. 
This automaton is defined by the tuple $(\vec{X},\vec{x}_0,\delta,F)$, where the carrier is $\vec{X}=2\times2$, the initial state is $\vec{x}_0\colon1\rightarrow \vec{X}$ with $\vec{x}_0(\star)=(0,0)$, the transition function $\delta\colon \vec{X}\rightarrow 2\rightarrow\vec{X}$ is defined for $\vec{x}\in \vec{X}$ and $i \in 2$ by $\delta(\vec{x})(i)=(i,\vec{x}[0]),$ and the characteristic predicate of the set of accepting states is $F\colon\vec{X}\rightarrow 2$, where $F(1,1)=1$ and $F(x,y)=0$ otherwise; i.e. $(1,1)$ is the only accepting state. This automaton is not minimal, since the states $(0,0)$ and $(0,1)$ are bisimilar.

\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        \node[state,initial] (00) {$(0,0)$};
        \node[state, below right of=00] (01) {$(0,1)$};
        \node[state, above right  of=00] (10) {$(1,0)$};
        \node[state, accepting, below right of=10] (11) {$(1,1)$};
        \draw (00) edge[bend left, above] node{1} (10)
        (00) edge[loop above] node{0} (00)
        (01) edge[bend left, left] node{1} (10)
        (01) edge[bend left, above] node{0} (00)
        (10) edge[bend left, above] node{1} (11)
        (10) edge[bend left, right] node{0} (01)
        (11) edge[loop above] node{1} (11)
        (11) edge[bend left, above] node{0} (01)
        ;\end{tikzpicture}
    \caption{An automaton which recognises the language $(0+1)^*11$.}
    \label{fig:ExampleLatent}
\end{figure}

Now, %assume that the programmer is malicious, and they purposely 
consider a symmetry in the state space which maps $(a,b)$ to $(\lnot a, \lnot b)$. This transformation models some fault which could be introduced by a malicious programmer. Formally, %the programmer applies a 
we define the transformation $m\colon \vec{X}\rightarrow\vec{X}$ for $\vec{x}\in \vec{X}$ by $m(\vec{x})=(\lnot \vec{x}[0],\lnot \vec{x}[1])$. 
State transformations are applied before behaviour is computed; thus, if the current state is $\vec{x}=(a,b)$, when we intend to check whether $\vec{x}$ is accepting, we instead check whether $(\lnot a, \lnot b)$ is accepting, and when we intend to compute $\delta(i)(\vec{x})$, we instead compute $\delta(i)(\lnot a, \lnot b)$. 

\begin{figure}[t]
    \centering
\begin{tikzpicture}
    \node[state, initial, accepting] (00) {$(0,0)$};
    \node[state, below right of=00] (01) {$(0,1)$};
    \node[state, above right  of=00] (10) {$(1,0)$};
    \node[state, below right of=10] (11) {$(1,1)$};
    \draw (00) edge[bend right, above] node{1} (11)
    (00) edge[bend right, above] node{0} (01)
    (01) edge[bend right, above] node{1} (11)
    (01) edge[loop below] node{0} (01)
    (10) edge[loop above] node{1} (10)
    (10) edge[bend right, above] node{0} (00)
    (11) edge[bend right, above] node{1} (10)
    (11) edge[bend right, above] node{0} (00)
    ;\end{tikzpicture}
\caption{Automaton that models the faulty implementation, which now recognises $\varepsilon+(0+1)^*10$.}
\label{fig:Transformed}
\end{figure}
Figure~\ref{fig:Transformed} shows a model of the faulty system. This automaton recognises the language of sequences of zeroes and ones that are either empty or end in 10; i.e., $\varepsilon+(0+1)^*10$. 
Before we explain why the automaton in Figure~\ref{fig:Transformed} models the faulty system, we can test if this system recognises sequences $\varepsilon+(0+1)^*10$. %$(0+1)(0+1)^*$. 
To do so, let us consider pairs of states $[\vec{x},\vec{y}]$ where $\vec{x}=(x_1,x_2)$ and $\vec{y}=(y_1,y_2)$ such that the pair $\vec{x}$ follows the original behaviour, i.e., without faults, while $\vec{y}$ follows the faulty behaviour. 
The initial state is $[(0,0),(0,0)]$. %, since $(1,1)$ replaces $(0,0)$ due to the fault. 
The trace of the sequence $00$ is 
\begin{align*}
   [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(0)\times\delta(0)}[(0,0),(0,1)]\\
   &\xrightarrow{\id\times m}[(0,0),(1,0)]\xrightarrow{\delta(0)\times\delta(0)}[(0,0),(0,1)]\\
   &\xrightarrow{\id\times m}[(0,0),(1,0)]\xrightarrow{F\times F}[0,0],
\end{align*}
so $00$ is rejected by both automata. %Note that $\delta(0)(1,1)=(0,1)$, but since $(1,0)$ replaces all read uses of $(0,1)$, we apply the fault directly. 
Now, if we receive the sequence $10$, the resulting state trace is 
\begin{align*}
    [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(1)\times\delta(1)}[(1,0),(1,1)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,0)]\xrightarrow{\delta(0)\times\delta(0)}[(0,1),(0,0)]\\
   &\xrightarrow{\id\times m}[(1,0),(1,1)]\xrightarrow{F\times F}[0,1];
\end{align*}
the faulty automaton accepts $10$, but the original automaton does not. 
The trace of the sequence $11$ is 
\begin{align*}
    [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(1)\times\delta(1)}[(1,0),(1,1)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,0)]\xrightarrow{\delta(1)\times\delta(1)}[(1,1),(1,0)]\\
   &\xrightarrow{\id\times m}[(1,1),(0,1)]\xrightarrow{F\times F}[1,0],
\end{align*}
so $11$ is accepted by the original automaton, but rejected by the faulty automaton. 
For the sequence $110$, the resulting state trace is 
\begin{align*}
    [(0,0),(0,0)]&\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{\delta(1)\times\delta(1)}[(1,0),(1,1)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,0)]\xrightarrow{\delta(1)\times\delta(1)}[(1,1),(1,0)]\\
   &\xrightarrow{\id\times m}[(1,0),(0,1)]\xrightarrow{\delta(0)\times\delta(0)}[(0,1),(0,0)]\\
   &\xrightarrow{\id\times m}[(0,1),(1,1)]\xrightarrow{F\times F}[0,1];
\end{align*}
the faulty automaton accepts $110$, but the original automaton does not. Finally, the original automaton rejects the empty sequence $\varepsilon$, but the faulty automaton accepts it, since 
\begin{align*}
    [(0,0),(0,0)]\xrightarrow{\id\times m}[(0,0),(1,1)]\xrightarrow{F\times F}[0,1].
\end{align*} 

% The map $m$ pairs each state with its corresponding faulty representation. %If there were no faults, the map $m$ would be the identity map. 
% The fault forces the state $(0,0)$ to behave like its image under $m$, i.e., the behaviour of $(0,0)$ in the faulty system should behave like $(1,1)$. Similarly, the state $(1,1)$ should behave $(0,0)$. 
%(We can alternatively see the function $m$ as a bad abstraction from the implementation.)

%There are now two final states: $(1,1)$ and $(0,1)$ since both states are preimages of $(1,1)$ under $m$.
We obtain the automaton shown in Figure~\ref{fig:Transformed} by ``copying'' the original behaviour from images of $m$ to their preimages. Figure~\ref{fig:ExampleWithFaults} shows this procedure for $(0,0)$ and $(1,1)$. This includes copying the behaviour under $\delta$ and under $F$. 

We preserve the initial state because $\vec{x}_0$ is a selection/construction/algebraic operation, not a behavioural/semantic/coalgebraic operation. We do not apply transformations to the results of algebraic operations to avoid aggregating the transformation erroneously due to composition of algebraic and coalgebraic operations. Consider the followign: the initial state $\vec{x}_0$ is of type $1\rightarrow\vec{X}$ which is algebraic, so the only way to apply $m$ to $\vec{x}_0$ is by composing it on the left, i.e., $m\circ \vec{x}_0(\star)$. Checking if the initial state is accepting in the original automaton corresponds to the expression $(F\circ\vec{x}_0)(*)$; however, the expression
\begin{align*}
    (F\circ m)\circ (m\circ\vec{x}_0)(\star)= (F\circ m)(1,1)=F(0,0)=0,
\end{align*}
applies $m$ twice, and it fails to properly check if the initial state of the faulty automaton is final. Instead, the correct expression is 
\begin{align*}
    (F\circ m)(\vec{x}_0)= (F\circ m)(0,0)=F(1,1)=1.
\end{align*}
% In other words, since $m(0,0)=(1,1)$, we copy the original behaviour of $(1,1)$ and we give it to $(0,0)$, including that $(1,1)$ is an accepting state; similarly, since $m(1,1)=(0,0)$ we copy the original behaviour of $(0,0)$ to $(1,1)$. 
% We do not change the initial state because 

\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        \node[state] (00) {$(0,0)$};
        \node[state, below right of=00] (01) {$(0,1)$};
        \node[state, above right  of=00] (10) {$(1,0)$};
        \node[state, below right of=10] (11) {$(1,1)$};
        \draw 
        (00) edge[above, bend left, dashed,color=gray] node[color=lightgray]{1} (10)
        (00) edge[loop above, dashed,color=gray] node[color=lightgray]{0} (00)
        % (01) edge[bend left, dashed,color=gray] (10)
        % (01) edge[bend left, below, dotted, color=gray](00)
        % (10) edge[bend left, dashed, color=gray] (11)
        % (10) edge[bend left, right, dotted, color=gray] (01)
        (11) edge[loop above, dashed, color=gray] node[color=lightgray]{1} (11)
        (11) edge[bend left, below, dashed, color=gray]node[color=lightgray]{0} (01)
        %Mutation Arrows
        (00) edge[color=gray, dotted] (11) 
        % (01) edge[color=red,dotted]  (10)
        % (10) edge[color=red, dotted]  (01)
        (11) edge[color=gray, dotted] (00)
        %New arrows
        (00) edge[bend right, below,color=red] node{0} (01)
        (00) edge[bend right, below,color=red] node{1} (11)
        (11) edge[bend right, above,color=red] node{0} (00)
        (11) edge[bend right, above,color=red] node{1} (10)
        % (11) edge[above] node{1} (1,0)
        % (11) edge[bend right, above] node[near start]{0} (00)
        ;\end{tikzpicture}
    \caption{Composition of the fault $m$ and the original behaviour for the states $(0,0)$ and $(1,1)$. The dotted, gray, bidirectional arrow in the centre models the effect of the fault $m$. The original behaviours appear as dashed, grey lines. The behaviour which results from the composition appears as solid, red lines.}
    \label{fig:ExampleWithFaults}
\end{figure}
We say that the faulty system is \emph{latent} with respect to the original system, since the application of the transformation $m$ reveals it, and $m$ is not the identity function. 
We cannot model every fault using transformations of the state space. The set of behaviours that we can obtain is limited; e.g., the behaviour of an automaton that accepts every sequence cannot be transformed by just transforming the state space. 
To transform an automaton which accepts all sequences into one that can reject some or all, we need a transformation of the \emph{behaviour}. 
Those transformations correspond to the arrow $F(X)\xrightarrow{b}F(X)$ in Figure~\ref{fig:TheArrow}. 
\todo[inline]{the final coalgebra is the place where spatial, behavioural, and coalgebras meet. Spatial transformations abstract a behaviour acting concurrently with the one we are currently studying, and that's why they are interesting to study.}
%However, systems revealed by transformations of type $F(X)\xrightarrow{b}F(X)$ are not latent by definition. %In this thesis, we are interested in seeing how far we can go with just carrier transformations; i.e., with latent behaviours.

We now present a general treatment for carrier transformations and latent behaviours in the context of $F$-coalgebras. 

\todo[inline]{Remark eventually that we cannot model every malicious behaviour of the programmer, only those that affect state, not functionality.}
\section{Latent $F$-coalgebras}
\todo[inline]{First write about the coalgebras and how they connect behaviours... then come back to this section.}
Coalgebras offer an interesting perspective for the study of systems. Given an $F$-coalgebra $(X,c\colon X\rightarrow F(X))$, each state $x\in X$ has an associated behaviour $c(x)\in F(X)$. In this section, we study the effect of a state transformation $m\colon X\rightarrow X$ over the $F$-coalgebra $(X,c)$. 

In terms of types, we can always compose the function $c$ with any carrier transformation $m$; the composition $c \circ m\colon X\rightarrow F(X)$ exists and is well defined. However, the behaviour of elements might be greatly affected. In particular, states which are bisimilar under $c$ might no longer be bisimilar under $c \circ m$. If $m$ preserves bisimilarity, then we say that $m$ is \emph{(behaviourally) consistent}.

\begin{definition}[Consistent Spatial Transformations]
Given an $F$-coalgebra $(X,c)$, any function of type $m\colon X\rightarrow X$ is a \emph{spatial transformation}. %A transformation $m\colon X \rightarrow X$ has \emph{finite support} iff $m(x)\neq x$ only for a finite number of $x\in X$. We denote the set of finitely supported transformations by $X^X_\omega$. 
A spatial transformation $m$ is \emph{(behaviourally) consistent} if and only if, whenever $x\sim_c y$, then $m(x)\sim_{c} m(y)$, for all $x,y \in X$. %We denote the set of consistent transformations by $X^X|_\sim$. %
\end{definition}
Henceforth, we consider only minimal systems, unless explicitly mentioned otherwise. 
\begin{corollary}
    If $(X,c)$ is a minimal $F$-coalgebra, then every spatial transformation %$m\colon X\rightarrow X$ 
    is consistent. 
\end{corollary}
A transformation function $m\colon X\rightarrow X$ changes the normal behaviour of $\mathbb{X}$, and it reveals the \emph{latent coalgebra of $\mathbb{X}$ under $m$}. 
\begin{definition}[Latent Coalgebra]
Given an $F$-coalgebra $\TheCoalgebra=(X,c)$ and a transformation $m$, the \emph{latent coalgebra of $\mathbb{X}$ under $m$} is $(X,c\circ m)$. 
\end{definition}
% \begin{align}
%     \mathbb{X}\circ m\triangleq(X,{(o\circ m, \delta\circ m })).
% \end{align}
The function $\TheLatentBehaviourOfIn{\cdot}{m}{c}\colon X\rightarrow \sigma F$ defines the \emph{latent behaviour} under $m$. The homomorphism $\TheLatentBehaviourOfIn{\cdot}{m}{\mathbb{X}}$ corresponds to the semantic mapping of the $F$-coalgebra $(X,c\circ m)$; that is, for $x\in X$, 
\begin{align}
\TheLatentBehaviourOfIn{x}{c}{m}\triangleq\TheBehaviourOfIn{x}{{c\circ m}}
\end{align} 

\begin{example}
\label{ex:Latent:TheExample}
Consider the automaton from Section~\ref{sec:Latent:Motivation} which recognises the language $(0+1)^*11$. Let $F$ be the functor $F(X)=2\times X^2$; we model this system with the $F$-coalgebra $(X,(F,\delta))$, where $X=2\times2$ and $(F,\delta)\colon X\rightarrow 2\times X^2$, defined for $(x,y\in X$ by
\begin{align}
    F(x,y)&\triangleq x \land y\\
    \delta(x,y)(i)&\triangleq (i,x).
\end{align}
Just like its automaton counterpart, this $F$-coalgebra is not minimal, since $(0,0)$ and $(0,1)$ are bisimilar
There are $|X|^{|X|}=256$ different spatial transformations, but that does not imply the existence of 256 different latent coalgebras; e.g., the transformations $\Delta_{(0,0)}$ and $\Delta_{(0,1)}$ yield isomorphic latent coalgebras. 
The transformation $m(x,y)=(\lnot x,\lnot y)$ reveals the latent coalgebra where 
\begin{align}
    (F\circ m)(x,y)&= \lnot x \land lnot y\\
    (\delta\circ m)(x,y)(i)&= (i,\lnot x).
\end{align}
The behaviour of states change when $m$ acts on $X$. In particular, the image of state $(0,0)$ under the semantic mapping is no longer the language $(0+1)^*11$ but $\varepsilon +(0+1)^*10$.
\end{example}
% \todo[inline]{There is no notion of distance or how different behaviours are in this setting. Things either are equal/isomorphic or they are not.}

LBA of an $F$-coalgebra $(X,X\xrightarrow{c} F(X))$ is the study of the effect that a spatial transformation $m\colon X\rightarrow X$ has over the behaviour of states in $X$, i.e., the shift in semantics from $c$ to $c\circ m$. It is also possible to change behaviour by composing $c$ with a \emph{behaviour transformation} $b\colon F(X)\rightarrow F(X)$ on the left. Both $(X,b\circ c\colon X\rightarrow F(X))$ and $(X,b\circ c\circ m\colon X\rightarrow F(X))$ are $F$-coalgebras, since the type requirement is satisfied. The effect of behaviour transformations in arbitrary systems are beyond the scope of this work. Nevertheless, there are systems where behaviour transformations and spatial transformations coincide: final $F$-coalgebras.

%\subsection{Latent Coalgebras of Final $F$-coalgebras}
A final $F$-coalgebra $(\sigma F, 1)$ has a behaviour function $1\colon \sigma F \rightarrow \sigma F$ that is an isomorphism. Since $\sigma F \simeq F(\sigma F)$, it naturally follows that 
\begin{align}
    \sigma F\rightarrow \sigma F \simeq \sigma F\rightarrow F(\sigma F) \simeq F(\sigma F)\rightarrow F(\sigma F).    
\end{align}
In other words, in the carrier of the final $F$-coalgebra, spatial transformations ($\sigma F\rightarrow \sigma F$), behavioural transformations ($F(\sigma F)\rightarrow F(\sigma F)$) and $F$-coalgebras ($\sigma F\rightarrow F(\sigma F)$) are in a one-to-one correspondence. 

Intuition tells us that $1\colon \sigma F \rightarrow F(\sigma F)$ should correspond to $\id_{\sigma F}\colon \sigma F\rightarrow \sigma F$ and should correspond to $\id_{F(\sigma F)}\colon F(\sigma F)\rightarrow F(\sigma F)$. The general form is given by the following proposition.
\begin{proposition}
    For every $F$-coalgebra $(\sigma F, c)$, there are transformations $m\colon \sigma F\rightarrow \sigma F$ and $b\colon F(\sigma F)\rightarrow F(\sigma F)$ such that the diagram in Figure~\ref{fig:FinalEquivalence} commutes.
\end{proposition}
\begin{proof}
    Since $1\colon \sigma F\rightarrow F(\sigma F)$ is an isomorphism, by taking $m=1^{-1}\circ c$ and $b=c\circ 1^{-1}$, the diagram in Figure~\ref{fig:FinalEquivalence} commutes.
\end{proof}
\begin{corollary}
    Every $F$-coalgebra $(\sigma F, c)$ is a latent coalgebra of $(\sigma F, 1)$ under some spatial transformation $m\colon \sigma F\rightarrow \sigma F$.
\end{corollary}

\begin{figure}[t] 
    \centering
    \begin{tikzcd}[column sep=1.5cm, row sep=1.5cm]
         \sigma F
            \arrow[r,"m"]
            \arrow[dr,"c"]
            \arrow[d,"1"']
        &\sigma F
            \arrow[d,"1"]
        \\
         F(\sigma F)
            \arrow[r,"b"']
        &F(\sigma F)
            %\arrow[u,"1^{-1}"']
    \end{tikzcd}
    \caption{Every $F$-coalgebra $(\sigma F, c)$ can be revealed from the final coalgebra $(\sigma F,1)$ by means of a transformation $m$ or a transformation $b$. In other words, it suffices to use spatial transformations $m$ and the final $F$-coalgebra to reveal all $F$-coalgebras of $\sigma F$, so behavioural transformations $b$ are unnecessary.}
    \label{fig:FinalEquivalence} 
\end{figure}
This property is exclusive to the carrier of the final coalgebra, because of the reversibility of the final map $1$, which formalises a correspondence between state and behaviour. For an arbitrary $F$-coalgebra $(X,c)$, only some latent $F$-coalgebras can be revealed by spatial transformations $m\colon X\rightarrow X$.

%\subsection{$F$-Coalgebras as Endofunctions}
Given a final $F$-coalgebra $(\sigma F, 1)$ and an arbitrary coalgebra $(\sigma F, c)$, the spatial transformation $\omega\colon \sigma F\rightarrow \sigma F$ defined by $\omega\triangleq 1^{-1}\circ c$ implements $c$. The identity spatial transformation implements $1$. This duality between $F$-coalgebras and spatial transformations in $\sigma F$ enables the composition of $F$-coalgebras in $\sigma F$.
%This treatment simplifies the composition of $F$-coalgebras in $\sigma F$. 

%When we compose $F$-coalgebras we are applying their behaviour functions sequentially. 
Given two $F$-coalgebras $(\sigma F, c_1)$ and $(\sigma F, c_2)$ whose respective spatial transformation implementations are $\omega_1$ and $\omega_2$, the composition $\omega_2\circ \omega_1$ gives rise to the following equivalent concepts:
\begin{itemize}
    \item the $F$-coalgebra $(\sigma F, c_2\circ 1^{-1}\circ\omega_1)$,
    \item the latent coalgebra of $(\sigma F, c_2)$ under $\omega_1$,
    \item the latent coalgebra of $(\sigma F, 1)$ under $\omega_2\circ \omega_1$.
\end{itemize}
In summary, we can represent $F$-coalgebras whose carrier is $\sigma F$ by endofunctions in $\sigma F$, and we can reason about their composition as we would with functions in the monoid of endofunctions $(\sigma F\rightarrow \sigma F, \circ, \id)$.

\todo[inline]{Explain that this corresponds to the point of The Arrow: $!c$ takes you from $X$ to $\sigma F$, and you can use $\omega$ to reveal a latent coalgebra of $(\sigma F, 1)$. This arrow $\omega$ models the behavioural change from $!c$ to $!_{b\circ c\circ m}$.}
In the following, we return to arbitrary $F$-coalgebras $(X,c)$, but we keep in mind the following: when we reveal a latent coalgebra of $(X,c)$ under a spatial transformation $m$, we are implicitly sequentially composing the behaviour function $c$ with the behaviour function of the $F$-coalgebra implemented by $m$; first we apply $m$ and then we apply $c$.

\section{Latent-Behaviour Analysis}
\todo[inline]{Describe in terms of coalgebras an introduction for the three application topics we have: attacker classification, CPS redesign and Side-channel repair.}
LBA is the study of the effects that spatial transformations have on the behaviour of the system. Just like in geometry, some spatial transformations may preserve some properties, while others may completely destroy the functionality of the system. In this section, we present three ideas for LBA to study three aspects of systems: \emph{attacks and counter-attacks}, \emph{attacker classification}, and \emph{side-channel repair}.

Consider the system from Section~\ref{sec:Latent:Motivation} and it coalgebraic equivalent presented in Example~\ref{ex:Latent:TheExample}. This example has 256 different spatial transformations, which we can use to model attacks on the system. 
\todo[inline]{I dunno where I was going with this}

% {\color{blue} Working with endofunctions is nice because you can study e.g. those with finite support. Endofunctions with finite support finitely compose nicely, and you can use them to model incremental changes to behaviour.

% What I need to do though is to hint towards potential applications. This section describes that in final coalgebras it suffices to compose endofunctions to model behaviours. In arbitrary coalgebras however, we can 
% }
% Composition of $F$-coalgebras is non-commutative. 
% \begin{theorem}[Fundamental Theorem of Latent-Behaviour Analysis]
%     \label{theo:Fundamental}
%     The semantic map-ping of the $F$-coalgebra $(X,c\circ m\colon X\rightarrow F(X))$ factors through the semantic mapping of the $F$-coalgebra $(m(X),c\colon m(X)\rightarrow F(m(X)))$
%     \todo[inline]{This probably needs to use bounded functors.}
% \end{theorem}
%This composition is in general not commutative.

% Consider an example in automata: we define $m\colon \sigma F\rightarrow \sigma F$ such that 
% \begin{align*}
%     m(\phi)(w)=
% \begin{cases}
%     \phi(w), \quad \text{if $w$ ends in 1},\\
%     0,\quad \text{otherwise}.
%     % \lnot \phi(w), \quad \text{if $w\varepsilon$}\\
%     % \phi(w), \quad \text{otherwise}.
% \end{cases}
% \end{align*}
% In other words, $m$ removes all sequences that do not end in $1$ from the language characterised by $\phi$. We obtain $c=1\circ m$

% In the case of automata, what does it mean for $c(L)=L'$ Normally what we have is $L\mapsto (0|1, 0\mapsto L_0, 1\mapsto L_1)$. 

% \todo[inline]{Something is not right: In the case of automata, }


% , and such a set of revealed behaviours is determined by the available \emph{gadgets}.

% \section{Gadgets}
% In the context of return-oriented programming~(\cite{ROP}), a \emph{gadget} is a code snipped that is part of the original program, and it is exploited by attackers to hijack the control flow once they affect the return addresses of functions. In the context of LBA, given an $F$-coalgebra $(X,c)$, if $c$ defines the program, then the components of $c$ define the set of \emph{gadgets} we can use to change the behaviour of the system.
% \begin{definition}[Gadgets]
%     Let $\mathbb{X}=(X,c)$ be an $F$-coalgebra. 
%     A \emph{gadget of $\mathbb{X}$} is a pair $(x,c)$ where $x\in X$. %The set of \emph{gadgets of $\mathbb{X}$} by the graph of $c$. 
% \end{definition}

% A gadget $(x,c)$ is a behavioural building block. We can interpret the gadget $(x,c)$ as the action of applying $c$ at $x$, so $(m(x),c)$ models the action of applying $c$ to $m(x)$. 

% In the example presented in Section~\ref{sec:Latent:Motivation}, there are four gadgets. Each gadget gives each spatial transformation $m$ a chance to further alter the behaviour of the system. 
% \todo[inline]{Where do you want to go with this? It looks interesting, but not useful. }

% In the following, we work on arbitrary $F$-coalgebras $(X,c)$ and only consider spatial transformations to

% \todo[inline]{If we want $a$ to change with time there is no need to do anything fancy! We can enhance the carrier by doing $X'=X\times \mathbb{N}$ or $X'=X\times [X\rightarrow 2]$; with this, $X$ is enhanced by a natural number counter or a set of conditions to make the dynamics of the transformation coalgebra more interesting. Maybe there is even no need to do changes, it all depends on how informative $X$ is. let's see}

% \todo[inline]{This means that the problem becomes a "searching for the next candidate at every step" problem. Alternatively, you could learn to compose solutions too. }
% \todo[inline]{Maybe we can also do something exciting: eventuality -> at some point in time, the behaviour you want becomes apparent, i.e. $\TheBehaviourOf{x_0}^w=\rho$ for some $w$}

\subsection{Quantifying Robustness}
\todo[inline]{The idea is that if we can design attacks, that yield new systems, we can design counter attacks that perhaps return the original system back. This is an introduction to the TOPS papers and the one we worked with Martin before}
\begin{definition}[Behavioural Property]
    \label{def:Latent:BehaviouralProperty}
    Let $F$ be a functor for which a final $F$-coalgebra $(\sigma F, 1)$ exists. A \emph{behavioural property} $P$ is a function $P\colon \sigma F\rightarrow 2$. Given an arbitrary $F$-coalgebra $(X,c)$, we say that $x\in X$ satisfies the behavioural property $P$ if and only if $(P\circ !_c)(x)=1$.
\end{definition}
Behavioural properties come in all shapes and forms, and are often described using logics like LTL~\cite{LTL}. CTL~\cite{CTL}, and $\mu$ calculus~\cite{MuCalculus}. Let us for now assume that we have a set of behavioural properties $\mathcal{R}=\set{R_1, \ldots, R_n}$ which model both functional and security requirements of the system. We discuss concrete ways to define these behavioural properties in Chapters~\ref{ch:Classification} and \ref{ch:CPSRobustness}.

Consider the following problem: we are given an arbitrary $F$-coalgebra $(X,c)$, an initial state $x_0\in X$, and a set of behavioural properties $\mathcal{R}=\set{R_1, \ldots, R_n}$. Normally, we would check if $x_0$ satisfies all behavioural properties in $\mathcal{R}$, but now we consider a spatial transformation $m\colon X\rightarrow X$, and we want to check if $x_0$ still satisfies all the given behavioural properties in the resulting latent coalgebra revealed by $m$.

We might think that it suffices to check whether $(R_i\circ !_c)(m(x_0))=1$ for each requirement $R_i$, but that would be incorrect as illustrated by the following example.
\begin{example}[Wrong Verification]
    In the context of Example~\ref{ex:Latent:TheExample}, the functor is $F(X)=2\times X^2$ has a final $F$-coalgebra $(2^{2^*},(\varepsilon?,(\cdot)'))$ where $\varepsilon? \colon 2^{2^*}\rightarrow 2$ checks whether the empty sequence $\varepsilon$ belongs to the language and $(\cdot)'\colon 2^{2^*}\rightarrow (2\rightarrow {2^{2^*}})$ computes the Brzozowski derivative~\cite{BrzozowskiDerivative} of the language.  
    \todo[inline]{Maybe move to preliminaries?}
    Consider the behavioural property $R\colon 2^{2^*}\rightarrow 2$ defined by $R(\phi)\triangleq \phi \sim \varepsilon+(0+1)^*10$, for $\phi \in 2^{2^*}$. This property $R$ is not satisfied by any state of the original $F$-coalgebra, so $(R\circ !_c)(m(x_0))=0$, but $R$ is satisfied by $x_0$ in the latent coalgebra revealed by the spatial transformation $m$, since that is the language it recognises in the latent coalgebra. 
\end{example}

By separating state from behaviour, we can focus on attacks that affect state. 
\begin{definition}[Attacks]
    Given an $F$-coalgebra $(X,c)$, we define the set of its \emph{state-based attacks} corresponds to be the set of its spatial transformations, i.e., $X^X$. 
    We also define the set of its \emph{behaviour-based attacks} by $F(X)^{F(X)}$. 
    \end{definition}
In this context, LBA studies the effect of state-based attacks. Henceforth, when we refer to an attack, we implicitly mean a state-based attack (unless stated otherwise). In the particular case of final $F$-coalgebras, their state-based attacks coincide with their behaviour-based attacks. 

We know that an attack $m$ reveals a latent coalgebra $(X, c\circ m)$ which may or may not satisfy the same behavioural properties that $(X, c)$ satisfies. 
% Different $F$-coalgebras have different sets of attacks. In our framework, a minimal $F$-coalgebra $(X,c)$ has as many attacks as $|X|^{|X|}$.


\subsection{Classification of Attackers}
Not all spatial transformations affect behavioural properties in the same way. 
\todo[inline]{rewrite the following, it is outdated. Here we should provide a small introduction, not definitions and all that, right?}

Intuitively, an attacker can be modelled by the set of attacks they have at their disposal. However, we avoid defining attackers by enumerating their attacks, since there may be infinite, and instead we will define them by the set of components of the system that they control. 
    \begin{definition}[Attacker]
    Given a functor $F$ and an $F$-coalgebra $\mathbb{X}=(\vec{X},c)$, such that $\vec{X}$ has components $\Pi=\set{\pi_1, \ldots, \pi_n}$, an \emph{attacker} of $\mathbb{X}$, say $A$, is a {finite} subset of $\Pi$ whose semantics is a set of attacks defined by the function $\texttt{attacks}\colon \TheFinitePowersetOf{\Pi}\rightarrow\ThePowersetOf{X^X_\omega}$ as follows. 
    For $j\in \set{1, \ldots,  n}$ and all $x\in X$,
    \begin{align}
    %\texttt{attacks}(A)=\set{f\in X^X_\omega | \text{ $f$ is consistent, and if $\pi_j \not\in A$, then $f(x)[\pi_j]=x[\pi_j]$}}.
    \texttt{attacks}(A)=\set{f\in X^X_\omega | \text{ if $\pi_j \not\in A$, then $f(x)[\pi_j]=x[\pi_j]$}}.
    \end{align}
    %{\color{red}
    %equivalently
    %\begin{align}
    %\texttt{attacks}(A)=\set{f\in X^X_\omega | \text{if $f(x)[\pi_j]\neq x[\pi_j]$, then $\pi_j \in A$, for all $x\in X$}}.
    %\end{align}
    %}
    In other words, $A$ has access to the set of attacks that can only affect the components that $A$ has direct control of.
     \end{definition}
 \begin{example}[Attackers of the system from Section~\ref{sec:Latent:Motivation} and their Semantics]
 The carrier $2\times 2$ has two components, $\fst$ and $\snd$, so there are four attacker models: $\emptyset$, $\set{\fst}$, $\set{\snd}$ and $\set{\fst,\snd}$. The attacks of the attacker $\emptyset$ do not mutate any component, i.e., $\texttt{attacks}(\emptyset)=\set{\id}$, and the attacks of $\set{\fst}$ and $\set{\snd}$ only affect the first/second component, respectively. The attacker $\set{\fst,\snd}$ has access to all attacks.
 \end{example}

{\color{red}
There is an attacker model associated with latent vulnerabilities: attackers that can change the value of state variables, but not the program that defines the system. This later attacker would correspond to one that can arbitrarily change the coalgebra, and is in that sense a much stronger attacker. If the attacker can enforce any behaviour they want, it becomes too powerful to defend against; all coalgebras are vulnerable, and no fix is available. However, an attacker that exploits a latent vulnerability is a bit in the middle: it can change the coalgebra by means of a transformation/attack function, but only through those. In that sense, not every behaviour is at the reach of the attacker, only those who are latent.

We can do a further refinement: we can imagine attackers that control particular components of a state by partitioning states into controllable parts and observable parts
\todo[inline]{Is there a difference? We could show that every attacker that controls a component induces a transformation, and all transformations can be modelled by attackers that control a certain number of components. Right?}

%  \todo[inline]{Commented is the definition with ranges, but it is kinda complicated. For spectre, we define the strategy first, then we think of what attacker we are, and for vulnerabilities, we will define the attacker first, and then we find the strategy.}
% 
% \begin{definition}[Attacker]
%Given a functor $F$ and an $F$-coalgebra $\mathbb{X}=(\vec{X},c)$, such that $\vec{X}$ has components $\Pi=\set{\pi_1, \ldots, \pi_n}$, an \emph{attacker} of $\mathbb{X}$, say $A$, is a pairing of a {finite} subset of $\Pi$, namely $A[\Pi]$, and a map $A[\texttt{range}]$ that associates each component in $A[\Pi]$ with a range of possible values; formally, $A[\texttt{range}(\pi_j)]\subseteq \Pi_j$, for all $\pi_j \in A[\Pi]$. %Formally, the type of attackers is $\TheFinitePowersetOf{\Pi} \times \ThePowersetOf{\Pi \times \vec{X}}$
%
%The semantics of an attacker is given by the set of attacks defined by the function $\texttt{attacks}\colon \texttt{Attackers}\rightarrow\ThePowersetOf{X^X_\omega}$ as follows. 
%For $j\in \set{1, \ldots,  n}$,  
%\begin{align}
%\texttt{attacks}(A)&\triangleq\set{f\in X^X_\omega | \text{ if $\pi_j \not\in A$, then $f(x)[\pi_j]=x[\pi_j]$, for all $x\in X$}}\cap\\
%&\set{f\in X^X_\omega | \text{ if $\pi_j \in A$, then $f(x)[\pi_j]\in \texttt{control}(A)(\pi_j)$, for all $x\in X$}}
%\end{align}
%{\color{red}
%equivalently
%\begin{align}
%\texttt{attacks}(A)=\set{f\in X^X_\omega | \text{if $f(x)[\pi_j]\neq x[\pi_j]$, then $\pi_j \in A$, for all $x\in X$}}.
%\end{align}
%}
%In other words, we associate to $A$ the set of attacks where, if $A$ does not contain the component $\pi_j$, then the attacks cannot change the value of $\pi_j$ when mutating states.
% \end{definition}
% 
% 
%  \todo[inline]{We can refine this definition of attackers with $(\pi_j, Y_j)$, with $Y_j\subseteq X_j$, instead of just $\pi_j$. HoWEVER, I highly encourage against this, because it overcomplicates things unnecessarily.}
%  \todo[inline]{I like writing $j\in n$, but this means enumeration should start from 0...I can probably use that in my language though}


% %  \subsection{Attacks over Discrete Time Systems}
% %  \todo[inline]{DO NOT FORGET THAT YOU CAN ASSUME $x(t)\neq x(t+k)$ for all $k$, because otherwise, you would have taken a different decision before!!! it's like going on a loop on a chessboard.}
% % Recall that we model discrete time systems with pointed $\DTS$-coalgebras of the functor $\DTS=O\times X^I$ for some fixed sets $O$ and $I$. Instead of describing attacks as some general mapping over the carrier set, we might want to describe attacks as changes in the current state. We call this notion of individual transformation a \emph{strategy}, and it is formalised as follows:
% % \begin{definition}[Strategy]
% % Given a $\DTS$-coalgebra $\TheCoalgebra=(X,\gamma,\delta,x_0)$, a \emph{strategy} $\lambda$ consists of a sequence of attacks...
% % \todo[inline]{Why do I want this?? Strategies are useful representations of attacks...but why?}
% % \end{definition}

% \begin{proposition}[Every Strategy is an Attack]
% For all $\DTS$-coalgebras $\TheCoalgebra=(X,\gamma,\delta,x_0)$ and every strategy $\lambda\in\Lambda$\todo{complete}
% \end{proposition}
 
 \subsubsection{A Partial Order of Attackers}
 \todo[inline]{This should go on a different chapter}
\todo[inline]{We know how to quantify attackers in terms of exact latent behaviours, but latent behaviours themselves have an order (they are languages i.e. sets). What about the relationship among them? Do stronger attackers need to recognise more languages, what if a language implies another? how do attackers relate there then?}

\begin{definition}[Attack Ordering]
Given two attacks $m_1, m_2$ and an $F$-coalgebra $\TheCoalgebra$, we say that $m_1\lesssim_\TheCoalgebra m_2$ if and only if $\supp(m_1) \subseteq \supp(m_2)$, and $m_1(x)\sim_\TheCoalgebra m_2(x)$ for all $x\in \supp(m_1)$. In other words, any $x$ that $m_1$ mutates can also be mutated by $m_2$ in the same way, in the context of the coalgebra $\TheCoalgebra$. We omit the subscript $\TheCoalgebra$ when it is clear from the context, or it is irrelevant.
\end{definition}
This notion of attack ordering is a bit more general than one that uses equality (i.e., requiring $m_1(x)= m_2(x)$ instead of $m_1(x)\sim_\TheCoalgebra m_2(x)$), as it lets us focus directly on behaviour, and not on structure. If the coalgebra $\TheCoalgebra$ is minimal, then $m_1(x)= m_2(x)$ if and only if $m_1(x)\sim_\TheCoalgebra m_2(x)$, due to the coinduction proof principle.

\begin{definition}[Attack Execution]
Given an attacker $A$, an $F$-coalgebra $\TheCoalgebra=(X,c)$, and an arbitrary attack $m\in X_\omega^X$, we say that \emph{$A$ can execute the attack $m$} if and only if there exists an attack $m'\in \texttt{attacks}(A)$ such that $m\lesssim m'$.
%\begin{align}
%m' (x)\sim m (x), \quad \text{for all $x\in \supp(m)$}.
%\end{align}
%In such a case, we write $m'\lesssim m$.
\end{definition}
 
\begin{definition}[Attacker Ordering]
Let $\TheCoalgebra$ be an $F$-coalgebra whose components are $\Pi$. The partial order relation $\leq$ in the set of attackers $\TheFinitePowersetOf{\Pi}$ by its set inclusion, i.e. $A_1 \leq A_2$ if and only if $A_1 \subseteq A_2$. 
\end{definition}
This attacker ordering is \emph{monotonic} with respect to the \texttt{attacks} function: if $A_1 \leq A_2$, then any attack carried out by $A_1$ can be executed by $A_2$. %With it, we can define minimal attackers.

Monotonicity offers us mainly two advantages: 1) we can plan the order of attackers to be checked, and 2) we can propagate the results in case a solution fails.
\todo[inline]{Explain this better. You really need to have clear notions of solution and problems.}
% \begin{definition}[Minimal Attacker]
% \todo[inline]{Probably one of the most esoteric definitions here. It is wrt a particular problem? a particular attack, a property?}
% \end{definition}

%\todo[inline]{Should we just focus on DTS? NO!  The DTS I wanted to use does not have loops, so it is clear that we can keep doing this in the current modelling.}
}
% \begin{definition}[Emulation Problem]
% We say 
% \end{definition}
 
%  \section{Solving Latent Vulnerability Problems}
 
%  \subsection{Alternative formulations}
%  \begin{definition}[Target Value]
% Given an $F$-coalgebra $\TheCoalgebra=(X,c)$ with components in $\Pi$, a \emph{target value} is a proposition $x[\pi]==v$, modelled by the triple $(x,\pi,v)$ where $x\in X$, $\pi\in \Pi$ and $v$ is a value in the range of component $\pi$.
% \end{definition}
 
% \subsection{Exhaustive Search}
% Given an attacker $A$ of an $F$-coalgebra $\TheCoalgebra=(X,c)$ and a target behaviour $\sigma$, we could perform an exhaustive search over the domain of its attacks if the carrier $X$ is finite.  A naive, exhaustive search would choose an attack $m$, mutate $\TheCoalgebra$, then perform a bisimulation check to see if there exists a state $x$ such that its latent behaviour $\TheLatentBehaviourOfIn{x}{m}{\TheCoalgebra}$ is equal to $\sigma$.

% Since the search space is finite, if we cannot find an attack $m$ within the capabilities of $A$, then the system $\TheCoalgebra$ is safe with respect to $A$.

% \begin{example}
% \todo[inline]{For the example we can show that it can be solved}
% \end{example}


% \subsection{Using SMT Solvers}
% Due to our formulation, we have a perfect information deterministic game, like Chomp~\cite{Chomp}. Our idea is to leverage an SMT solver to give us a winning move for the attacker, or prove that such move does not exist. For the remainder of this section, we focus on $\DTS$-coalgebras.

% \todo[inline]{Rephrase this as a reachability problem. i.e. instead of a target value, use a set of goal states defined by the target values.}
% \todo[inline]{HERE I AM}
% \begin{definition}[Winning Latency Games]
% Let $A$ be an  attacker, $\TheCoalgebra=(X,\gamma,\delta,x_0)$ be a pointed $\DTS$-coalgebra, and consider a set of target values $(\pi_1,v_1),...,(\pi_n,v_n)$. We say that the attacker $A$ \emph{wins the latency game in zero steps} if and only if there exists an attack $m$ in $\texttt{attacks}(A)$ such that $m(x_0)[p_k]=v_k$, for $k=1..n$. If a solution is found in zero steps, then all target components $\pi_1$ to $\pi_n$ must be in control of $A$, i.e., $\set{\pi_1, \ldots, \pi_n}\subseteq A$.

% The attacker $A$ \emph{wins the latency game in $\tau$ steps given the inputs $(i_1, \ldots, i_\tau)$ with the attack $m$ at state $x_{\tau}$} if and only if there exists a sequence of states $(x_1, \ldots, x_\tau)$, where
% \begin{align}
% %m_{\tau+1}(x_{\tau +1})=x_\tau(
% x_{t+1}=\delta(m (x_{t}))(i_t), \quad \text{for $t=0..{\tau-1}$}
% \end{align}
% and
% \begin{align}
% m(x_\tau)[p_k]=v_k,\quad \text{ for $k=1..n$.}
% \end{align}
% \end{definition}


% \begin{proposition}[Composition through Emulation]
% \todo[inline]{There are several ways to compose attackers: through $\delta$ and through $m$. The message I want to carry across is the following: if you know that you can solve a latency game from a state $x$, then 
%  I already have a notion of winning over time, so I just need to emulate the attack of other attackers to reach my goal.}
% If an attacker $A$ can win a latency game in $\tau$ steps given the inputs $i_1, \ldots i_{\tau}$ in the pointed $\DTS$-coalgebra $(X,\gamma,\delta, x_{0})$ with an attack $m$, then an attacker $A'$ can win the same latency game in $\tau+t$ steps given the input $i_1, i_2, \ldots i_{\tau+1}$ in the pointed $\DTS$-coalgebra $(X,\gamma,\delta, x_{-t})$ if and only if 
% \begin{align}
% \delta
% \end{align}

% %Given a pointed $\DTS$-coalgebra $(X,\gamma,\delta, x_0)$, an attacker $A_0$ can win a given latency game in ${\tau+1}$ steps given the inputs $(i_1, \ldots, i_\tau, i_{\tau+1})$ with some attack $m$ at some state $x_{\tau+1}$ if and only if there exists an attacker $A_{\tau}$ that can win the given latency game in one step in the pointed $\DTS$-coalgebra $(X,m\gamma,\delta, x_{\tau})$.
% \end{proposition}
% \begin{proof}
% The main objective of $A_0$ is to reach state $x_{\tau}$ and from there 
% \end{proof}


%\begin{proposition}
%\label{sec:Incompleteness}
%Given an arbitrary $F$-coalgebra $\mathbb{X}=(X,c)$ and a behaviour $\rho\in \sigma F$, there may not exist a transformation $m\colon X\rightarrow X$ such that $\rho$ is a latent behaviour of $\mathbb{X}$ under $m$.
%\end{proposition}
%\begin{proof}
%We provide a counterexample for the opposite proposition, that is, there exists a transformation $m\colon X\rightarrow X$ such that $\rho$ is a latent behaviour of $\mathbb{X}$ under $m$, for all $F$-coalgebras and all behaviours in $\sigma F$. 
%Consider, for the functor $F=2\times \texttt{id}^2$, a single-state $F$-coalgebra that accepts all sequences; this $F$-coalgebra cannot display a latent behaviour different from its original behaviour.
%\end{proof}


\subsection{System Repair}
\todo[inline]{Enforcement is one of those problems where you have an original system and you want to still preserve the essence while changing the properties. What we do with side channels is this: we take a program, we slightly modify it, and we prove that we enforced something. I have to change things a bit here, because the program has to be the state, but that's ok, since I can model a coalgebra that counts the number of memory accesses and all that. }

\section{Future work}
\todo[inline]{This should go in the last chapter!}
We would like to consider two problems related to latent behaviours: 
\begin{itemize}
\item How can we use transformations ourselves to repurpose a system that is already been defined?
\item How can an attacker use transformations to force a behaviour they want?
\end{itemize}
\todo[inline]{Note that, ultimately, both questions need a method to solve an equation for a transformation. That is, given a target behaviour and an a source coalgebra, how do you solve the problem of finding a transformation that helps you display the behaviour you want? Is it even possible?}



